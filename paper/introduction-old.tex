
\section{Introduction}
Correlation clustering~\cite{Bansal-2002} also known as the multicut problem~\cite{chopra_1993_mp} 
is a basic primitive in computer vision~\cite{andres_2011_iccv,kroeger_2012_eccv,yarkony_2012_eccv,alush_2013_simbad} and data mining~\cite{Chierichetti-2014,Arasu-2009,Sadikov-2010} as a first step
towards understanding an image or data in general. 
The correlation clustering problem is the following:
Given an undirected edge weighted graph, 
where positive weights (\emph{attractive}) encourage the adjacent nodes to be in the same cluster
and negative weights (\emph{repulsive}) encourage the nodes to stay in different cluster, 
find the clustering of nodes such that the sum over weights of edges between clusters is minimized.
Note that this problem formulation does not included a predefined number of clusters.

Despite the clear mathematical formulation and nice properties of correlation clustering
to perform a one-shot agglomeration clustering,
the main draw back of correlation clustering is scalability~\cite{nunez_iglesias_2013}
which arise from the NP-hardness of the problem~\cite{Bansal-2002}.

In signed social networks, where positive and negative edges encodes friend and foe relationships, respectively,
correlation clustering is a natural way to detect communities~\cite{Chierichetti-2014,Chen-2012}.
Correlation clustering can also been used to cluster query refinements in web search~\cite{Sadikov-2010}.
Because social and web-related networks are often very huge, heuristic methods, \eg the PIVOT-algorithm~\cite{Ailon-2008},
are very popular~\cite{Chierichetti-2014}.

In computer vision applications, unsupervised image segmentation algorithms usually start with an over-segmentation
into superpixels (superregions), which are then clustered into ``perceptually meaningful''
regions by correlation clustering on sparse graphs.
Such an approach has been shown to yield
state-of-the-art results on the Berkeley Segmentation Database
\cite{andres_2011_iccv,yarkony_2012_eccv,alush_2013_simbad}.

Recently, Beier~\etal~\cite{beier_2014_cvpr} presented a promising 
approximative method called Cut, Clue \& Cut.
While this scales well for planar graphs, it does not for non planar graphs and has a bad any-time performance.
A further inherent drawback of this method is that the subproblems are not limited in their size.
%
Consequently, partition problems on large scale data, \eg
huge volume images in computational neuroscience~\cite{kroeger_2012_eccv}
or social networks~\cite{Leskovec-2010}, 
are not tractable, because the runtime explodes or the 
approximations are far away from being useful.

In the present work we will suggest some alternative approaches to deal with large scale correlation clustering problems.
In the end we ill present a method that can be combined with any other correlation clustering method and 
allows to reduce the overall problem to a sequence of correlation clustering problems which are by magnitudes smaller.


\textbf{Contribution:}
In the present work we present some novel approaches that are designed for large scale correlation clustering problems.
First, we define a novel energy based agglomerative clustering algorithm that monotonically increase the energy.
With this at hand we show how to improve the anytime performance of Cut, Clue \& Cut.
Second, we introduce cluster-fusion moves, which extend the original fusion moves~\cite{Lempitsky-2010} 
used in supervised segmentation to the unsupervised case and give a polyhedral interpretation of this algorithm.
We propose two versatile proposal generators, and evaluate the proposed methods on existing and new benchmark problems.
That experiments show that we can improve the computation time by one to two magnitudes without worsening the segmentation 
quality significantly.


% Given an edge weighted graph, positive weights (\emph{attractive})
% encourage the adjacent nodes to be in the same 
% connected component, while negative weights (\emph{repulsive}) encourage
% the nodes to stay in different connect components.
% Therefore the sign of the weights encodes if two
% nodes should be merged or not and the magnitude of the weights encodes
% the certainty of this desire.
% The objective of correlation clustering / multicuts
% is finding the cut with a minimal sum of cut edge weights.
% The number of connected components / clusters is discovered
% from the weights ( rewrite?!?).
% Correlation clustering / the multicut is NP-hard \cite{???}.
% %
% Despite the NP-hardness, correlation clustering has been 
% successfully used for
% \begin{inparaenum}[(i)]
%     \item partitioning a superpixel region adjacency graph~\cite{andres_2011_iccv,kroeger_2012_eccv}
%     \item with optional long range repulsive edges~\cite{andres_2013_emmcvpr}.
%     \item Alush and Globerger showed how to average multiple segmentations with the multicut objective~\cite{alush_2012_pami}.
%     \item Multicuts can also be used for interactive segmentation~\cite{bagon_2011_arxiv},
%     \item for co-segmentation~\cite{glassner_2011_cvpr}
%     \item and to cluster sparse and graphs~\cite{???}.
% \end{inparaenum}


% Despite the nice properties of correlation clustering
% to perform a \say{one-shot agglomeration of supervoxels} ~\cite{nunez_iglesias_2013},
% the main draw back of correlation clustering is scalability~\cite{nunez_iglesias_2013}.
% Existing solvers for correlation clustering do not scale for non planar graphs.
% Even state of the art approximate move making algorithm fail 
% to give good approximations non planar graphs.
% When increasing the problem sizes, either the runtime explodes or the 
% approximations are far away from being useful.


% \textbf{Contribution:}
% \begin{inparaenum}[(i)]
% \item Within this work we propose a fast and scalable move making algorithm for correlation clustering,
% \item which generalized  fusion moves \cite{???} to correlation clustering problems.
% \item We reduce the inference to a series of moves where
% each moves optimizes over a subspace spanned by the current best solution
% and a proposal solution.
% \item We propose two versatile proposal generators,
% \item and show how to optimize these moves.
% \item We give a polyhedral interpretation of this algorithm,
% \item and evaluate the proposed method 
% on existing benchmark problems.
% \item We show state of the art any time performance on those instances.
% \end{inparaenum}[(i)]

\textbf{Outline:} {\bf If we are short of space, the following can be ommited:}
In sec.~\ref{sec:problem_formulation} we will give a 
detailed problem definition where we introduce 
the correlation clustering objective.
In sec.~\ref{sec:related_work} we will 
discuss existing methods for correlation 
clustering and briefly explain the concept of fusion moves.
In sec: ~\ref{sec:cc_fm} we describe our proposed
method and show the properties of the algorithm.
In sec.~\ref{sec:exp} we show an evaluation
of the method on existing parameter  and discuss the effects of parameters.
Future work will be discussed in sec. \ref{sec:future} and
we will conclude in ~\ref{sec:conclusion}.
%-------------------------------------------------------------------------

\section{Notation and Problem Formulation}\label{sec:problem_formulation}
Let $G=(V,E, w)$ be a weighted graph of nodes $V$ and edges $E$.
%
The function $w : E \rightarrow \mathbb{R}$ assigns a weight to each edge.
A positive weight expresses the desire that two adjacent nodes should
be merged, whereas a negative weight indicates
that these nodes should be separated into two different regions.
%
A \emph{subgraph} $G_A = \{A, E_A, w\}$ consists
of nodes $A \subseteq V$ and edges $E_A := E\cap (A\times A)$.
%
A segmentation of the graph $G$ can by either given by an 
node labeling $l \in \mathbb{N}^{|V|}$
or an edge labeling $y \in\{0,1\}^{|E|}$.  
An edge labeling is only consistent if it contains no dangling edges~\cite{kappes_2013_arxiv}.
We denote the set of all consistent edge labelings by $P(G)\subset\{0,1\}^{|E|}$.
The convex hull of this set is known as the \emph{multicut polytope} $MC(G) = \textrm{conv}(P(G))$.


%$\rho_y : P(G) \to P(G_y)$
%$\rho_y^{-1} : P(G_y) \to P(G)$


% \begin{itemize}
%   \item Multicut in computer vision, applications, sparse segmentation -> IMPORTANT PROBLEM
%   \item Problem: Existing Methods does not scale, even CGC. - Large scale 3d problems
%   \item Contribution: Fast scalable method using novel fusion moves for correlation clustering
% \end{itemize}

% Def: Graph, weighted graph, cut, multicut 

Given a weighted graph $G=(V,E,w)$ we consider the problem of segmenting $G$ such that the costs
of the edges between distinct segments is minimized. This can be formulated in the node domain
by assigning each node $v$ a label $l_v \in \mathbb{N}$
\begin{align}
  l^* &= \argmin_{L \in \mathbb{N}^{|V|}} \sum_{ (i,j) \in E } w_{ij} \cdot [l_{i} \neq l_{j}], \label{eq:nodeproblem}
\end{align}  % y_{ij}^* &=& [l_{u} \neq l_{v}] 
or in the edge domain, by label each edge $e$ as cut $y_e=1$ or uncut $y_e=0$ 
\begin{align}
  y^* &= \argmin_{y \in P(G)} \sum_{ (i,j) \in E } w_{ij} \cdot y_{ij} \label{eq:edgeproblem}.%\\ 
\end{align}
As shown in~\cite{kappes_2013_arxiv} both problems are equivalent, but formulation \ref{eq:nodeproblem}
suffers from ambiguities in the formulation~\cite{kappes_2011_emmcvpr}.

% The exist an surjective mapping from a node-label $l$ to edge-labeling $y$ and
% a bijective mapping from a partitioning of $V$ to vertices of the multicut polytope $MC$.
% Consequently, 
% (i) problems \ref{eq:nodeproblem} and \ref{eq:edgeproblem} are equivalent
% and (ii) the node-labeling is not unique for a given partitioning and introduce some
% ambiguities.

% \subsubsection{Multicut Objective}

% The multicut / correlation clustering objective 
% can be formulated in different ways.



% \paragraph{Edge Indicator Variables:}
% \begin{center}
%     \begin{eqnarray}
%         y^* &=& \argmin_{y} \sum_{ e_{ij} \in E } w_{ij} \cdot y_{ij} \\
%         s.t.:& & y \in \textit{Multicut Polytope} \nonumber
%     \end{eqnarray}
% \end{center}

% \paragraph{Fully Connected Graph:}
% \begin{center}
%     \begin{eqnarray}
%         y^*   & = & \argmin_{y} \sum_{ i<j \in V } w_{ij} \cdot y_{ij} \\
%         s.t.: &  & y_{ij} + y_{jk} < y_{i,k} \quad \forall i, j, k   \nonumber
%     \end{eqnarray}
% \end{center}

% \paragraph{Node Coloring:}
% \begin{center}
%     \begin{eqnarray}
%         l^* &=& \argmin_{L} \sum_{ e_{ij} \in E } w_{ij} \cdot [l_{u} \neq l_{v}] \\
%         y_{ij}^* &=& [l_{u} \neq l_{v}]  
%     \end{eqnarray}
% \end{center}

\input{inputs/fig_notation.tex}

\section{Related Work}\label{sec:related_work}%
%
Due to the ambiguity of formulation~\ref{eq:nodeproblem},
a major branch of research has focused on solving 
relaxations of eq.~\ref{eq:edgeproblem}.
To keep the objective and system of inequalities small, they 
work on sparse graphs and
use cutting plane methods
in combination with (integer) linear programming and efficient 
separation procedures~\cite{kappes_2011_emmcvpr,andres_2011_iccv,kappes_2013_arxiv}.

With no time restrictions and integer constraints these methods can solve the problem to global optimality.
For huge problems both, separation and solving the ILP in each round, becomes very time consuming.

For planar problems, Yarkony \etal~\cite{yarkony_2012_eccv} 
suggested a column generating strategy for the outer LP-relaxation
that includes all cycle-inequalities of problem \ref{eq:edgeproblem}.
The column generation base on solving planar max cut instances.
While this method is fast, 
it only solve a relaxation of the problem and so requires additional rounding strategies,
lacks of a practical stopping condition for the column generation,
and most important  is restricted to planar problems.

An other branch of research uses move making algorithm 
to optimize correlation clustering~\cite{bansal_2004_ml,beier_2014_cvpr,Kernighan-1970}.
Starting with an initial segmentation, auxiliary problems are solved that 
strictly improve the segmentation.

Bansal and Bagon propose a modified $\alpha-$expansion~\cite{bansal_2004_ml} 
algorithm suitable for correlation clustering, that allows all variables to 
change to cluster $\alpha$ in a single move. While the authors claim that this
scales to large scale data, in~\cite{beier_2014_cvpr} it has been shown that 
this is not the case in general. This is not surprising because the auxiliary 
problems can have as many variables as the original problem. 
 
A more efficient move making method has been presented by Beier \etal~\cite{beier_2014_cvpr}.
Their Cut, Glue and Cut method iteratively re-optimizes the cuts between adjacent clusters of the current solution.
While this method scales better then  modified $\alpha-$expansion, it still faces three problems:
Firstly, the subproblems can be as large as the original problem,
secondly, the subproblems are max-cut problems on non-planar graphs that are NP-hard 
and even the used approximation has high polynomial complexity.
This limits the method, to be applicable to huge problems. The same holds for the 
method of Kernighan and Lin~\cite{Kernighan-1970}. 

   % \begin{itemize}
   % \item Multicut~\cite{kappes_2011_emmcvpr}
   % \item Expand and Explorer~\cite{bagon_2011_arxiv}
   % \item Fast Planar CC~\cite{yarkony_2012_eccv}
   % \item Break and Conquer \cite{alush_2013_simbad}.
   % \item Cut Glue And Cut~\cite{beier_2014_cvpr}
   % \end{itemize}

For energy minimization problems fusion moves have become increasingly popular~\cite{Lempitsky-2010,kappes_2014_ws}.
For many large scale computer vision applications fusion moves lead to good approximations
with state of the art any time performance~\cite{kappes_2014_ws}.

The fusion move algorithm iteratively fuse the current best solution with a proposal solutions
by optimizing over the subspace spanned by the two labeling. 
Due to the ambiguity of a node-labeling, fusion moves can not be applied directly for correlation clustering.
We will show how to overcome this point later.

\input{inputs/fig_hc_alg.tex}

Outside computer vision greedy methods has been suggested for correlation clustering problems, see \cite{Elsner-2009} for an overview.
A common greedy approach~\cite{Soon-2001,Ng-2002,Elsner-2008} is to randomly permute the nodes and than assign 
iteratively each node to an existing cluster or create a new cluster if costs cannot be decreased by assigning to a cluster.
%Common assigning strategies are:
%\emph{BEST}; assign to cluster which is linked by the most positive edge~\cite{Ng-2002},
%\emph{FIRST}; Assign to the cluster which is first linked by a positive edge~\cite{Soon-2001}, and
%\emph{VOTE}; Assign to cluster that minimizes objective function~\cite{Elsner-2008}.
%
The PIVOT Algorithm~\cite{Ailon-2008} iterate over all nodes in random order.
If the node is not assigned it construct a cluster containing the node and all its 
unassigned positively linked neighbors.  
%
%Typically these algorithms started for many random permutations, 
%and pick the clustering with best objective value.

A widely use post-processing method is  Best One Element Move (BOEM)~\cite{Gionis-2007}.
Start with an initial clustering one node is removed from a cluster and reassigned to an existing or new cluster such that the costs are minimized.
BEOM stops if no move can decrease the costs.
