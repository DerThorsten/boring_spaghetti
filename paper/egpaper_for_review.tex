\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{eso-pic}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{placeins}


% Include other packages here, before hyperref.
\usepackage{my_macros}
\usepackage{paralist}
\usepackage{amsthm}
% \usepackage{dirtytalk} fah: my miktex didn't like this; and we don't need it here. 
%\usepackage{framed}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{setspace}
%for tikz
\usepackage{tikz,pgfplots}
\usepackage{pgfplotstable}
\usepackage{filecontents}
%\usepackage{scrextend}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\pdfpageattr{/Group <</S /Transparency /I true /CS /DeviceRGB>>}
\usepackage{everypage}
\AddEverypageHook{%
  \makeatletter%
  \special{pdf: put @thispage <</Group << /S /Transparency /I true /CS /DeviceRGB>> >>}%
  \makeatother%
}%

\newcommand{\footlabel}[2]{%
    \addtocounter{footnote}{1}%
    \footnotetext[\thefootnote]{%
        \addtocounter{footnote}{-1}%
        \refstepcounter{footnote}\label{#1}%
        #2%
    }%
    $^{\ref{#1}}$%
}

\newcommand{\footref}[1]{%
    $^{\ref{#1}}$%
}
\usetikzlibrary{arrows,positioning,automata,shadows,fit,shapes}
\usetikzlibrary{arrows,petri,topaths}
\usetikzlibrary{positioning,fit,calc}
\usetikzlibrary{shapes.arrows,chains,decorations.pathreplacing,fadings}
\usetikzlibrary{calc, matrix, backgrounds}




%%%%%%global tikz styles

\tikzstyle{eBlack}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=black!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eNotCut}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=green!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eBlue}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=blue!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eCut}=[very thick,dotted,minimum size = 0.5cm,inner sep = 0pt,draw=black, font=\small,align=left, draw=red!70!black, line width=1mm]

\pgfplotsset{every axis/.append style={
  every axis y label/.style = {at={(ticklabel cs:0.5)}, rotate=90, anchor=south},
  axis x line = {bottom},
  axis y line = {left},
  tick align = outside,
  ymajorgrids = true,
%  legend style = {draw=none, at={(1.05, 0.5)}, anchor=west, font=\small},
  legend style = {font=\tiny},
  legend columns = 1,
  every axis plot/.append style = {line width=1pt},
  label style = {font=\small},
  tick label style={font=\small},
  scaled ticks = false,
}}

% Two Colored Circle Split 
\makeatletter
\tikzset{circle split part fill/.style  args={#1,#2}{%
 alias=tmp@name, 
  postaction={%
    insert path={
     \pgfextra{% 
     \pgfpointdiff{\pgfpointanchor{\pgf@node@name}{center}}%
                  {\pgfpointanchor{\pgf@node@name}{east}}%            
     \pgfmathsetmacro\insiderad{\pgf@x}
      \fill[#1] (\pgf@node@name.base) ([xshift=-\pgflinewidth]\pgf@node@name.east) arc
                          (0:180:\insiderad-\pgflinewidth)--cycle;
      \fill[#2] (\pgf@node@name.base) ([xshift=\pgflinewidth]\pgf@node@name.west)  arc
                           (180:360:\insiderad-\pgflinewidth)--cycle;            
         }}}}}  
 \makeatother  

%\usepackage{tkz-berge}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\definecolor{shadecolor}{rgb}{0.01,0.199,0.1}
\usepackage{xargs} 
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage{bm}% Ã¤ndert \boldsymbol
\def\arraystretch{0.8}
\renewcommand{\tabcolsep}{2pt}
\newcommand{\thickline}{2pt}
\newcommand{\scatterplotpath}{./scatterplots/}

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}
\newcommand{\OR}{\textrm{ or }}

% \cvprfinalcopy % *** Uncomment this line for the final submission


\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand{\realplot}[1]{
\begin{tikzpicture}
    \begin{axis}
        \addlegendimage{empty legend}\addlegendentry{Matrix #1}
        \addplot {0};
        \addplot {1};
        \addplot {2};
        \addplot {3};
    \end{axis}
\end{tikzpicture}}  

% \newcommand{\anytimeplot}[1]{
%   \addplot[color=brown,mark=x] table[x=time,y=HC]{data3/knott-3d-300.data};              \addlegendentry{HC}
%   \addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data3/knott-3d-300.data};          \addlegendentry{HC-CGC}
%   \addplot[color=red,mark=x] table[x=time,y=CGC]{data3/knott-3d-300.data};               \addlegendentry{CGC}
%   \addplot[color=gray,mark=o] table[x=time, y=ogm-KL]{data3/knott-3d-300.data};          \addlegendentry{KL}
%   \addplot[color=purple,mark=x] table[x=time, y=MCR-CCFDB]{data3/knott-3d-300.data};     \addlegendentry{MC-R}
%   \addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data3/knott-3d-300.data};       \addlegendentry{MC-I}
%   \addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC]{data3/knott-3d-300.data};    \addlegendentry{Fusion-HC-MC}
%   \addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC]{data3/knott-3d-300.data};    \addlegendentry{Fusion-HC-CGC}
%   \addplot[color=orange,mark=x] table[x=time, y=DYNCC-WS-MC]{data3/knott-3d-300.data};  \addlegendentry{Fusion-WS-MC}
%   \addplot[color=orange,mark=x] table[x=time, y=DYNCC-WS-CGC]{data3/knott-3d-300.data};  \addlegendentry{Fusion-WS-CGC}
% }
\newcommand{\anytimeplot}[1]{
  \addplot[color=brown,mark=x] table[x=time,y=HC]{data3/#1.data};              \addlegendentry{HC}
  \addplot[color=black,mark=square] table[x=time,y=HC-CGC]{data3/#1.data};          \addlegendentry{HC-CGC}
  \addplot[color=red,mark=x] table[x=time,y=CGC]{data3/#1.data};               \addlegendentry{CGC}
  \addplot[color=gray,mark=o] table[x=time, y=ogm-KL]{data3/#1.data};          \addlegendentry{KL} 
  \addplot[color=yellow!50!black,mark=square] table[x=time, y=ogm-mcfusion-HC-CF*]{data3/#1.data};  \addlegendentry{Fusion}
  \addplot[color=purple,mark=o] table[x=time, y=MCR-CCFDB]{data3/#1.data};     \addlegendentry{MC-R}
  \addplot[color=blue,mark=o] table[x=time, y=MCI-CCIFD]{data3/#1.data};       \addlegendentry{MC-I}
  \addplot[color=green,mark=o] table[x=time, y=DYNCC-HC-MC]{data3/#1.data};    \addlegendentry{CCFusion-HC-MC}
  \addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC]{data3/#1.data};    \addlegendentry{CCFusion-HC-CGC}
  \addplot[color=orange,mark=o] table[x=time, y=DYNCC-WS-MC]{data3/#1.data};  \addlegendentry{CCFusion-WS-MC}
  \addplot[color=pink,mark=x] table[x=time, y=DYNCC-WS-CGC]{data3/#1.data};  \addlegendentry{CCFusion-WS-CGC}
}
%  \addplot[color=yellow!50!black,mark=o] table[x=time, y=ogm-mcfusion-HC-CF*]{data3/#1.data};  \addlegendentry{Fusion}
  %\addplot[color=green!50,mark=o] table[x=time, y=PIVOT*]{data3/#1.data};          \addlegendentry{PIVOT-BOEM}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}
%%%%%%%%% TITLE
\include{my_macros.tex}
%\title{Correlation Clustering with Dynamic Super-Nodes (DySNCC)}
\title{Fusion Moves for Correlation Clustering}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
  \color{red} \textbf{TODO:}
Correlation clustering, or multicut partitioning, is the NP-hard problem of partitioning an undirected graph or image with positive / attractive and negative / repulsive edge weights such that the sum of cut edge weights is minimized. We here present a move-making heuristic that uses cheaply generated proposal clusterings to iteratively and monotonously improve upon the best previously found clustering. A valid partitioning is maintained at all times, and solutions close to the global optimum are obtained faster than with any published technique. 
    
%We address the problem of partitioning a  graph
%   into a previously unknown number of clusters.
%   Among all partitions, the one with the minimal 
%   sum of of cut edge weights is chosen. 
%   This problem is known as correlation clustering 
%   or multicut.
%   We propose a general framework to find
%   high quality approximate solutions for 
%   this NP-hard problem based on a move making algorithm:
%   We use candidate solutions from a proposal generator
%   to iteratively improve the best observed solution similar
%   to fusion moves.
%   The proposed solver outperforms any other solver
%   w.r.t. to any time performance.
%   The solutions found by this solver are close
%   to global optimal solutions w.r.t. energy
%   and problem specific measurements as VI for
%   image segmentation problems.

\end{abstract}

\input{introduction-new.tex}
%\input{introduction-old.tex}
%\input{introduction-fred.tex}

\input{inputs/fig_hc_alg.tex}
\section{Energy Based Hierarchical Clustering}\label{sec:ehc}
Agglomerative hierarchical clustering (HC) is widely used
in graph / image segmentation~\cite{arbelaez_2006}.
In each step, the edge with the highest weight $w$ is
contracted (green edges in Fig.~\ref{fig:hc_alg}).
Doing so, parallel edges edges can occur.
In agglomerative clustering, weights of
parallel edges are merged into single edges.
For image segmentation, the length
weighted mean is used to do this update~\cite{arbelaez_2006}.

While we, contrary to~\cite{arbelaez_2006}, directly work on energies, we are interesting in an 
agglomeration with respect to our energy function~\ref{eq:edgeproblem}.
For this we propose to use energy based agglomeration
with the following update rule:
Whenever there are multiple edges between 
a pair of nodes, these edges are merged into a single edge
by summing up their weights, since we 
minimize the sum of the cut edges.
We call HC with this update method Energy base Hierarchical Clustering (EHC).

We stop EHC if the highest edge weight is
smaller or equal to zero  (blue edge in Fig.~\ref{fig:hc_alg}). Any further edge
contraction leads to worse energies.

% Hierarchical clustering is fast, and 
% due to the agglomeration of edge weights, 
% {\color{red} hierarchical clustering is robust against noise}.
% {\color{yellow} [ First most similar nodes are merged...]
% In agglomerative clustering, weights of
% parallel edges are merged into single edges.}
% For image segmentation, the length
% weighted mean is used to do this update [ref].

% [We contrary on those works work directly on energy functions and that why ...]
% We propose to use Energy Based Hierarchical Clustering (EHC) to find
% solutions for correlation clustering.


% To make EHC follow the energy, we propose 
% the following update rule:
% Whenever there are multiple edges between 
% a pair of nodes, these edges are merged into a single edge
% by summing up their weights, since we 
% minimize the sum of the cut edges.
% The algorithm stops if the highest edge weight is
% smaller or equal to zero  (green edge in fig. ~\ref{fig:hc_alg}). Any further edge
% contraction leads to worse energies.

Given the intrinsic greediness of hierarchical clustering, 
and the fact that EHC does only local decisions, it is 
sensitive against noise and we cannot expect optimal solutions.

But EHC is very fast, and can be used to initialize
CGC~\cite{beier_2014_cvpr}. Excessive time in CGC
is spend in the \emph{cut phase} to solve the 
first 2 coloring on the complete graph.
As shown in Sec.~\ref{sec:exp},
allowing CGC to start from the EHC solution
can improve performance drastically.



% Common cluster distances
% \begin{itemize}
% \item Single-Link: Nearest Neighbor - their closest members.
% \item Complete-Link: Furthest Neighbor - their furthest members.
% \item Centroid: Distance between centroids
% \item Group Average: average of all cross-cluster pairs.
% \end{itemize}

%------------------------------------------------------------------------
\section{Correlation-Clustering-Fusion}\label{sec:cc_fm}

Fusion move algorithms~\cite{Lempitsky-2010} are a popular technique 
for large scale discrete energy minimization problems.
They iteratively fuse two node labelings by optimizing over the label space spanned by those.
Different fusion algorithms vary in the proposals and method used for the auxiliary fusion problem~\cite{kappes_2014_ws}.

As fusion algorithms work with node labelings, % \cf Eq.~\ref{eq:nodeproblem},
we face the problem that the node coloring is ambiguous and has no semantic meaning.
This causes that a fusion move is not well defined, because different choices of colors 
lead to different auxiliary problems, as shown in Fig.~\ref{fig:fusion_abiguty}.
 
In the following, we propose a more suitable fusion move for correlation
clustering which works on the edge domain.
It allows to change all edge labelings, which are active in at least one of the two labelings.
%
Given two proposal solutions $y'$ and $y''$,
$\mathcal{E}^0_{\breve{y}}$ is the set of edges
which are uncut in $y'$ and $y''$.
%
\begin{align}
\breve{y}_{ij}    & = \max\{ y_{ij}', y_{ij}''\}  & \forall {ij}\in E\\  % y' \cup y'' \\
\mathcal{E}^0_{\breve{y}}  & =  \{ (i, j) \; | \; \breve{y}_{ij} = 0 \}
\end{align}
%
The fusion move for correlation clustering is solving Eq.~\ref{eq:edgeproblem}
with additional \emph{must-link constraints} for all edges in $\mathcal{E}^0_{\breve{y}}$.
%
\begin{align}
  y^* &= \argmin_{y \in P(G)} \sum_{ (i,j) \in E } w_{ij} \cdot y_{ij} \label{eq:fusion_move_a}.\\ 
      &\quad \textrm{s.t.} \quad y_{ij} = 0 & \forall (i, j) \in \mathcal{E}^0_{\breve{y}} \nonumber
\end{align}
%
By construction, solving Eq.~\ref{eq:fusion_move_a} cannot increase the energy,
because $y'$ and $y''$ are feasible solutions.
%\begin{align}
%  \sum  w_{ij} \cdot y^*_{ij}  \leq \min \left( \sum  w_{ij} \cdot y'_{ij} ,  \sum   w_{ij} \cdot y''_{ij} \right)
%\end{align}
%

The  correlation clustering fusion algorithm (CCFusion) iteratively improve the best solution by
fusing it with proposal solution.
The inherent difference to classical fusion~\cite{Lempitsky-2010} is how we define the fusion.
We fuse the segmentations according to Eq.~\ref{eq:fusion_move_a}.

A further difference is how we efferently calculate the correlation clustering fusion move and how we generate proposals.
Both will be discussed next.



\input{inputs/fig_fusion.tex}

%\textbf{old}
%
%Motivation Using Fusion moves -> problem ambiguity
%
%A consistent edge labeling $y$ defines a segmentation of $V$ by enumerating the connected components 
%in $G|_y=(V,\{e\in E|y_e=0\}$ by $l_v = \#(v)$, where $\#(v)$ denotes the number of the connected component of the %node $v\in V$.
%
%We define the contradiction of graph $G_y=(V_y,E_y)$
%with $V_y=\{\#(v)|v\in V\}$ and $E_y=\{\#(v),\#(u)|uv\in E, y_{uv}=1\})$.

%\input{inputs/fig_alg_graph.tex}


\subsection{Fast Optimization of CCFusion Moves} \label{sec:fast_optimization}

Eq.~\ref{eq:fusion_move_a} can be solved efficiently, since 
we can work on a coarser graph, where all nodes which are connected
via must-link constraints are merged into single nodes.
This coarser graph is constructed by contracting all must-link edges
(see Fig.~\ref{fig:move_graph}).


\begin{definition}\emph{(Contradicted Graph)}
Given a weighted graph $G=V,E,w)$ segmentation of $G$ given by $y\in P(G)$,
we denote by $S: V \to \mathbb{N}$ a mapping from the nodes to the segments.
We define the contradiction of graph $G_y=(V_y,E_y, \bar{w})$
by $V_y=\{S(v)|v\in V\}$, $E_y=\{S(u)S(v)|uv\in E\}$, and 
$\forall \bar{u}\bar{v}\in E_y: \bar{w}_{\bar{u}\bar{v}}=\sum_{uv\in E, S(u)=\bar{u},S(v)=\bar{v}}w_{uv}$ 
\end{definition}

\begin{definition}\emph{(Back Projection)}
Given a segmentation $\bar{y}$ of a contradicted graph $G_y=(V_y,E_y)$.
We define the back projection $\rho^G$ from $\bar{y}$ to a segmentation of original graph  $G=(V,E)$
by 
\begin{align}
\rho^G_{uv}(\bar{y})=\left\{ 
\begin{array}{ll}
\bar{y}_{S(u)S(v)}& \textrm{ if }S(u) \neq S(v)\\
0                & \textrm{ else}
\end{array}
\right.
\end{align}
\end{definition}

\begin{theorem}[Equivalence]
The optimal multicut $\bar{y}^*$ on the contracted graph $G_y$
is equivalent to the optimal multicut $y^*$ in the original graph $G$ 
with additional must link constraints ($y^* \leq y$).
%
\begin{proof}
Since $y^*$ fulfills all  must link constraints, we have  $y^*\cdot w = \rho^{-1}_y(y^*)\cdot \bar{w}$.
Consequently, $y^*\cdot w = \rho_y(\bar{y}) \cdot w$ and  $\rho^{-1}_y(y^*)\cdot \bar{w}= \bar{y}\cdot\bar{w}$.
\end{proof}
%
\end{theorem}


TODO:
Here we need to proof that it is equivalent 
to optimize the contracted graph !



\input{inputs/fig_contraction.tex}
\input{inputs/fig_projection.tex}



\input{inputs/fig_move_graph.tex}







%-------------------------------------------------------------------------
%\subsection{Fusion Move Solver}







%-------------------------------------------------------------------------
\subsection{Proposal Generators}

As discussed in \cite{Lempitsky-2010}, proposals
should have two properties: \emph{quality} 
and \emph{diversity}.
The quality / energy of the individual proposals
ensures low energy solutions since the
result of the fusion cannot be higher then
the energy of the current best solution.
Diversity between the individual proposals
reduces the chances to get stuck in local minima.
For correlation clustering fusion we add a third
property: \emph{size}.
The size of the contraction graph directly
depends on the number of connected components
in the proposal solution and the current best solution.
The extreme  case is a proposal where each 
node is in a separate connnected component.
Solving the fusion move with such a proposal
is equivalent to solving the original problem.
Solving the fusion move with a proposal with 
a single connected component will result 
in the current best solution.
Therefore the size of the proposals
should be small enough, such that solving
eq.~\ref{eq:edgeproblem} can
be done fast enough, but large enough to make
meaningful moves (??? this last sentence needs to be rewritten).




%\begin{algorithm}
%    \begin{scriptsize}
%        \caption{Proposal Generators}\label{alg:proposal_gen}   
%        \begin{algorithmic}[1]
%            %\Require $J(x) \leq J(x')$
%            %\Ensure $J(\hat{x}) \leq J(x)$
%            %\vspace{0.3cm}
%            \Procedure{Rand2Coloring}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $x'= \argmin\limits_{\bar{x}} \sum\limits_{e_{ij} \in E } \tilde{w}_{ij}[\bar{x}_i \neq \bar{x}_j]  [x_i = x_j]   $
%
%            $ \quad\quad s.t.\quad x_i \in \{0, 1\} \forall i $
%            \State \textbf{return} $x'$
%            \EndProcedure
%            %
%            %
%            \vspace{0.3cm}
%            \Procedure{RandEdgeWeightedWatersheds}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $ getRandomSeeds$
%            \State $ runEdgeWeightedWs$
%            \EndProcedure   
%            %
%            %
%            \vspace{0.3cm}
%            \Procedure{RandHierarchicalClustering}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $\hat{G}=(\hat{E},\hat{V}) \gets G=(E,V)$
%            \State $\hat{W} \gets W$
%            \While{$|\hat{V}|>\gamma$ \textbf{and}  $\max(\hat{W})>\theta$ }
%                \State $\hat{G}=(\hat{E},\hat{V}),\hat{W} \gets 
%                    \textbf{\scriptsize{contract}}(\hat{G},\hat{W},  \argmax\limits_{\hat{E}}(\hat{W}) )$
%            \EndWhile
%            \State $x' \gets \textbf{\scriptsize{getClusterResults}}(???) $ 
%            \EndProcedure
%        \end{algorithmic}
%    \end{scriptsize}
%\end{algorithm}



\noindent \textbf{Randomized HierarchicalClustering (RHC):}
%\subsubsection{Randomized HierarchicalClustering (RHC)}
%
To generate fast energy aware proposals we can use energy
based hierarchical clustering (EHC) as defined in sec.~\ref{sec:ehc}.
EHC follows the energy function, therefore the \emph{quality}
of the proposals is high.
To get \emph{diversity} among the different proposal,
we add normal distributed noise with a standard deviation of $\sigma_{ehc}$
to each edge weight.
To get proposals of the desired \emph{size}, we can use a
different stop condition in EHC, and stop when a certain number of connected
components is reached.

%\subsubsection{Randomized MaxCut  (RMC)}
%
%To get energy aware proposals we can use max cuts.
%The max cut objective is the same as
%the multicut objective, but only two 
%node colors are allowed.
%Therefore solutions of the max cut objective
%might be useful proposals.
%To create different proposals we set 
%the weight of edges which are cut 
%in the best solution to zero.
%In this way we favor solutions 
%different form the current best. 
%In addition we either add noise permute a certain number of weights.

\noindent \textbf{Randomized Watersheds (RWS):}
%\subsubsection{Randomized Watersheds (RWS)}
%
The edge weighted watershed algorithm \cite{meyer_2013}
with random seeds can be used to get
cheap proposals.
To improve \emph{quality} we do not use $n$ seeds distributed uniformly
over all nodes but use the following.
Draw $n/k$ random edges only the negative edges,
and give the two nodes of each ``seed-edge'' a different seed.
Doing so, a random subset of negative edges is forced
to be cut within each proposal.
For additional \emph{diversity} randomness, noise can be added to
the edge weighs.

%\input{inputs/fig_hc.tex}

\subsection{Properties and Polyhedral Interpretation}
An alternative interpretation of our method is shown in Fig.~\ref{fig:polyheadral}.
In each iteration the current and proposed segmentation define an inner polyheadral 
approximation of the original multicut polytope. 
Optimizing over this polytope is the same problem as the original one, but much smaller.
Furthermore, the costs does not change and and improvement in the smaller polytope will 
be the same in the original graph.
The choice of the proposal defines the shape of the auxiliary polytope. 
In the given toy example, the first (red) polytope give a huge improvement, the second proposal
defines the blue polytope which does not lead to an improvement. 
The third proposal generates the green polytope that includes the global optimal solution.

This procedure is fundamental different to common polyhedral multicut methods~\cite{kappes_2011_emmcvpr,kappes_2013_arxiv}, 
which tighten a outer relaxation of the multicut polytope and contrary to our method do not operate in the feasible domain. 



\begin{figure}
\centering
\input{polytope-tikz.tex}
\caption{Each move can be interpreted as an optimization of an inner polyhedral optimization.
Each polyhedral approximation includes the current vertex. Starting with $y_0$ we optimize over the red polytope 
and find $y_1$ as optima. When optimize over the blue polytope we stay in $y_1$ as optima.
When optimizing over the green polytope we find $y_2$ which we will never leaf again or any polytope containing $y_2$. 
}
\label{fig:polyheadral}
\end{figure}





% \begin{theorem}[Monotone]
% Let $y'$ and $y''$ be two proposal solutions and  $y^*$ the optimal fused segmentation.
% Than $y^*$  will never decrease the energy:
% $y^* \cdot w \leq  \min( y'\cdot w,  y''\cdot w) $ 
% %
% \begin{proof}
% The feasible set of the fusion move includes per definition  $y'$ and $y''$.
% If $y'$ or $y''$ would have lower multicut cost than $y^*$, $y^*$ would not be optimal 
% and that why not the propose segmentation of a fusion.
% \end{proof}
% %
% \end{theorem}


%\begin{remark}[Fix-point (pointless to me)]
%Let $Y$ be the set of possible proposals, than
%$y'$ is a fix-point if $y'=\arg\max_{y\in P(G_{y'\OR y''})} y\cdot w$ for all $y''\in Y$
%\end{remark}



\begin{remark}[Optimality]
Let $y'$ be the current and $y''$ the proposed segmentation.
If the optimal solution $y^*$ lies in $P(G_{y' \OR y''})$ than a optimal fusion move will return $y^*$.
\end{remark}



\section{Experiments}\label{sec:exp}
In our experiments we compare to the following methods withpublic available implementation.

For \textbf{CGC}~\cite{beier_2014_cvpr} we used the public available implementation\footnote{\label{opengm-cvpr2014}\url{https://github.com/opengm/opengm/tree/cgc-cvpr2014}}
of the Beier~\etal and for \textbf{KL}~\cite{Kernighan-1970} the implementation in OpenGM\footlabel{opengm-master}{\url{https://github.com/opengm/opengm}}.
For integer multicuts (\textbf{MC-I}) and relaxed multicuts (\textbf{MC-R})~\cite{kappes_2013_arxiv} we try the public available implementation in OpenGM\footref{opengm-master}
of Kappes~\etal. We realize that their implementation has some limitations on large problems and make the following modifications.
Firstly, we use \emph{index-min-heap}~\cite{Sedgewick-2011} within the shortest path search by the Dykstra algorithm - this gives a speed up for MC-R.
Secondly, we follow~\cite{kroeger_2012_eccv} and search for shortest paths and add those only if they are non-chordal instead of searching for the shortest non-chordal path
during the separation procedure. Fig.~\ref{fig:at:knott-450b} show the improvements with our modifications compared to the implementation in OpenGM for the knott-3d-450 dataset.
This procedure is one magnitude faster, but might cause a few extra outer iterations.
In~\cite{kroeger_2012_eccv}. this has been used for MC-I only. 
For MC-R this search procedure is not sufficient and need to be followed by a search for a shortest non-chordal paths.
From the field of data-mining we compare to the PIVOT-algorithm~\cite{Ailon-2008} followed by a round of BOEM~\cite{Gionis-2007} denoted by \textbf{PIVOT-BOEM}.
We use the public available code of Micha Elsner\footnote{\url{http://www.ling.ohio-state.edu/~melsner/resources/correlation-readme.html}}.
While this implementation uses full adjacency matrixes it does not scale as well as the algorithm can and therefor can not be applied on all datasets.
We also run classical fusion moves~\cite{Lempitsky-2010} (\textbf{Fusion}) and select distinct labels for the two candidate segmentations.

As reported in~\cite{beier_2014_cvpr}, CGC is faster and gives better energies then PlanarCC~\cite{yarkony_2012_eccv} and Expand \& Explore~\cite{bagon_2011_arxiv}.
Therefore we exclude those in our experiments.

We compare this methods to the following methods suggested in the present paper.
%
Energy Based Based Hierarchical Clustering (\textbf{EHC})
as described in sec.~\ref{sec:ehc}.
%
CGC warm started with the solution from EHC denoted by \textbf{EHC-CGC}.
%
The proposed correlation cluster fusion algorithm with EHC-based and watershed-based proposals
 and MC-I and CGC as subproblem solvers denoted by 
\textbf{fusionCC-HC-MC},
\textbf{-HC-CGC},
\textbf{-WS-MC}, and 
\textbf{-WS-CGC}, respectively.
We set the size of the proposals fix to $10\%$ of the original problem size
and the standard derivation of the random edge noise to $1.5$.


 \begin{figure}[t]
    \centering
    \begin{tikzpicture}
    \begin{semilogxaxis}[  mark size=1pt,
     height= 4cm, 
    restrict y to domain=-80000:1000,
   %   restrict x to domain=10:4000,
    xlabel = {runtime},
    xmin = 10,
    xmax = 4100,
    ymax = 0,
    ymin = -80000,
    legend to name = ledgendPositionMC,
    legend columns=4,
    width = 0.9\columnwidth,
    scaled ticks = false
    ] 
    \addplot[color=red,mark=x] table[x=time, y=MC-CCFDB-o*]{data3/knott-3d-450b.data};          \addlegendentry{MCR-old}
    \addplot[color=orange,mark=o] table[x=time, y=MC-CCFDB-n*]{data3/knott-3d-450b.data};          \addlegendentry{MCR-new}
    \addplot[color=blue,mark=x] table[x=time, y=MC-CCIFD-o*]{data3/knott-3d-450b.data};          \addlegendentry{MCI-old}
    \addplot[color=cyan,mark=o] table[x=time, y=MC-CCIFD-n*]{data3/knott-3d-450b.data};          \addlegendentry{MCI-new}

    \end{semilogxaxis}
    \end{tikzpicture}
  \begin{center}
  \hypersetup{linkcolor = black}
  \ref{ledgendPositionMC}
  \hypersetup{linkcolor = red}
  \end{center}
    \caption{Comparison of the Multicut implementation of OpenGM and 
    our modified implementation, which can deal better with large scale problems. 
    However, for large scale problems it still does not scale.}
    \label{fig:at:knott-450b}
  \end{figure}

All experiments were run on Intel Core i5-4570 CPUs
with 3.20 GHz, equipped with 32 GB of RAM.
In our evaluation we make not use of multiple threads.
The methods were stopped if they exceed 30 minutes at the next possible interrupt point.

\subsection{Parameter Choice for CCFusion}
Beside the choice of the proposal generator and fusion method CCFusion has some more parameters, which need to be set.
The most crucial one is the number of segments in the proposal. For HC we also have to set the noise which is use to generate diversity.
Fig.~\ref{fig:parameterchoice} shows a evaluation of the impact of this parameters for a single instance of knott-3d-450 averaged over several random seeds.
The runtime many depend on the number of clusters in the proposal (Fig.~\ref{fig:parameterchoice} left), which controls the size of the auxiliary move problems.
The level of noise has no major impact on the runtime.
The energy of the final solution improves with finer proposals since this increase the search-space of the moves.
Although the level of noise has to be large enough to generate diverse proposals but also not to large to generate proposals with low energy.
As shown in Fig.~\ref{fig:parameterchoice} right the useful parameter set is quite large. This allows us to use the same parameters for \emph{all}
experiments. However we would like to note, that in practice we can improve the performance by adjust these parameters for the specific problem setting.
%
%
\begin{figure}[th]
\centering
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-time2.pdf}}
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-value2.pdf}}
\caption{Empirical evaluation of the impact of noise used for proposal generation and proposal size.
  Proposals with many segments causes longer runtime. Noise seemed not to be a critical parameter but should be selected large enough.
}
\label{fig:parameterchoice}
\end{figure}

\subsection{Social Networks and Network Clustering}
A application for large scale correlation clustering are social networks.
We consider two of those networks from the Stanford Large Network Dataset Collection\footnote{\url{http://snap.stanford.edu/data/index.html}}.
Both networks are given by weighted directed graphs with edge weights $-1$ and $1$. 
%
The first network is called \emph{Epinions}. 
This is who-trust-whom online social network of a a general consumer review site Epinions.com. 
Each directed edge $a\to b$ indicated that user $a$ trusts  or does not trust user $b$ is the edge-weight is positive or negative, respectively.
The network contains $131828$ nodes and $841372$ edges from which $85.3\%$ are positively weighted.
%
The second network is called \emph{Slashdot}. 
Slashdot is a technology-related news website know for its specific user community. 
In 2002 Slashdot introduced the Slashdot Zoo feature which allows users to tag each other as friends or foes. 
The network was obtained in November 2008 and contains $77350$ nodes and $516575$ edges from which $76.73\%$ are positively weighted.

We consider the problem to cluster this graphs such that positively weighted edges ($E^+_{\to}$) link inside and negatively weighted edges ($E^-_{\to}$) between clusters.
In other words friends and people who trust each other should be in the same segment and foes and non-trusting people in different clusters.
% 
To compensate the high impact of nodes with high degree we can normalize the edge weights such that each person has the same impact to the overall network, by enforcing.
\begin{align}
  \sum_{i\to j \in E_{\to}} |w_{i\to j}| &= 1&\forall i\in V, deg^{\textrm{out}}(i)\geq 1 
\end{align}
We define the following energy function
\begin{align}
 J(y) &= \sum_{i\to j \in E^+_{\to}} y_{ij}\cdot w_{i \to j} +  \sum_{i\to j \in E^-_{\to}} (y_{ij}-1)\cdot w_{i \to j} \nonumber\\
      &= \sum_{ij \in E} y_{ij}\cdot \underbrace{(w_{i \to j}+w_{j \to i})}_{w_{ij}} + \textrm{const}
\end{align}
which is zero if the given partitioning does not violated any relation and larger otherwise.

{\color{red}\textbf{TODO: Discussion}}


As another example for network clustering we use the modularity-clustering models from~\cite{kappes_2014_benchmark_arxiv} which are small but fully connected.

{\color{red}\textbf{TODO: Discussion}}



\subsection{2D and 3D Image Segmentation}
To segment images or volumes into a previously
unknown number of clusters, correlation clustering
has been used~\cite{andres_2011_iccv,kroeger_2012_eccv}.

Starting from a super-pixel/-voxel segmentation,
correlation clustering finds the clustering with the lowest energy.
The energy is based on a likelihood of merging adjacent super-voxels.
Each edge has a probability to keep adjacent segments separate ($p(y_{ij} =1)$)
or to merge them ($p(y_{ij} = 0)$).
The energy function is defined as following:
\begin{align}
 J(y)  &= \sum_{ij \in E} y_{ij}\cdot \underbrace{  log\left( \frac{p(y_{ij} =0)}{p(y_{ij} =1)}\right) + log \frac{1-\beta}{\beta}  }_{w_{ij}}
\end{align}
Where $\beta$ is used as a prior~\cite{andres_2011_iccv}.

We use the public available benchmark instances from~\cite{kappes_2013_benchmark_cvpr,kappes_2014_benchmark_arxiv}.
For 2D images, we took the segmentation problems on the Berkeley Segmentation Database~\cite{martin_2001} called \emph{image-seg}~\cite{andres_2011_iccv,kappes_2013_benchmark_cvpr}.
For 3D volume segmentation we took the models \emph{knott-3d-150},\emph{-300} and \emph{-450} from~\cite{kroeger_2012_eccv,kappes_2014_benchmark_arxiv} as well as the large
instance from the \emph{3d-seg} model~\cite{andres_2011_iccv,kappes_2013_benchmark_cvpr}. These instances have underling cube sizes of  $150^3$, $300^3$, $450^3$, and $900^3$, respectively.
We also request larger instances from the authors of~\cite{kroeger_2012_eccv} which kindly provide us the dataset~\emph{knott-3d-550} with cube size  $550^3$.
More information of the size of instances is given in Tab.~\ref{tab:instance_sizes}.

{\color{red}\textbf{TODO: Discussion}}

\begin{table}[H]
   \tiny
   \centering
   \caption{Datasets used for evaluation}
   \label{tab:instance_sizes}
   \begin{tabular}{llllc}
      \toprule
         Dataset          &     \#Nodes     & \#Edges  & \#Instances  & Planar        \\ 
      \midrule 
         image-seg        &     156-3764        & ???              & 100          & $\bullet$    \\ 
         knott-150        &     572-972         & ???              & 2            & $\times$ \\
         knott-300        &     3846 - 5896     & ???              & 2            & $\times$ \\
         knott-450        &     15150-17070     & ???              & 2            & $\times$ \\
         knott-550        &     27286 - 31249   & ???              & 2            & $\times$ \\
         3d-seg           &     101220          & ???              & 1            & $\times$ \\
         socialnets       &     77350 - 131828  & 516575 - 841372  & 2            & $\times$ \\  
      \bottomrule
   \end{tabular}
\end{table}

\begin{table}[H]
   \tiny
   \centering
   \caption{Evaluation of Variation of Information (VI) for datasets with available ground-truth.}
   \label{tab:eval}
   \begin{tabular}{lllllll}
      \toprule
         Dataset          &  image-seg   & knott-3d-150 & knott-3d-300   & knott-3d-450 & knott-3d-550 &3d-seg\\
      \midrule 
         PIVOT-BOEM       &   $ 4.9633$  &    $ 2.9936$ &       --       &              &              &  --\\ 
         HC               &   $ 2.5967$  &    $ 1.5477$ &    $ 2.3513$   &    $ 2.9155$ &              & $       2.8395$\\
         HC-CGC           &   $ 2.5164$  &    $ 0.9052$ &    $ 1.7636$   &    $ 2.2256$ &              & $       1.7603$ \\
         CGC              &   $ 2.5247$  &    $ 0.9267$ &    $ 1.8822$   &    $ 2.3104$ &              & $       6.8908$ \\
         KL               &   $ 2.6432$  &    $ 2.0648$ &    $ 4.1318$   &    $ 4.9270$ &              & $       7.1057$\\
         FUSION           &      --      &    $ 2.8787$ &    $ 4.0744$   &    $ 4.6616$ &              & $       6.5366$ \\
         MC-R             &   $ 2.5471$  &    $ 0.9178$ &    $ 1.6369$   &    $ 2.8710$ &              & $       6.5058$\\   
         MC-I             &   $ 2.5367$  & $\bf 0.9063$ & $\bf 1.6352$   & $\bf 2.0037$ &              & $       4.3319$\\  
         FusionCC-HC-MC   &   $ 2.5319$  &    $ 0.9629$ &    $ 1.6516$   &    $ 2.0801$ &              & $\bf    1.3347$ \\  
         FusionCC-HC-CGC  &$\bf 2.4961$  &    $ 0.9679$ &    $ 1.7673$   &    $ 2.3809$ &              & $       2.1347$ \\  
         FusionCC-WS-MC   &   $ 2.5340$  &    $ 0.9629$ &    $ 1.6742$   &    $ 2.0739$ &              & $\bf    1.3334$ \\  
         FusionCC-WS-CGC  &   $ 2.5192$  &    $ 1.0585$ &    $ 2.1344$   &    $ 2.7487$ &              & $       3.3514$ \\      
      \bottomrule
   \end{tabular}
\end{table}

%\begin{center}
%    \begin{figure}
%        \begin{center}
%            \begin{subfigure}[b]{0.45\linewidth}
%                \includegraphics[width=1.0\linewidth]{images/-010.jpg}
%            \end{subfigure}
%            \quad
%            \begin{subfigure}[b]{0.45\linewidth}
%                \includegraphics[width=1.0\linewidth]{images/-030.jpg}
%            \end{subfigure}
%        \end{center}
%    \caption{
%        Raw FIBSEM data and correlation clustering result of the model from \cite{kroeger_2012_eccv%}
%    }
%    \end{figure}
%\end{center}
%
%\newpage



\input{anytimefigure2.tex}


% \begin{figure}
% \input{scatterplots/knott-3d-450.tex}
% \caption{Values and runtime for the 8 knott-3d-450 instances. Note that we use for DYNCC a defensive stopping condition.
% A more aggressive one would lead to much faster runtime with only a bit worse values.
% DYNCC find solutions with less than distance 100 to the optimum a magnitude faster than the state of the art, which produce poor results on hard instances with a 1 hour time limit.
% }
% \end{figure}



%\subsection{Pixel-wise Multicuts}
%\input{inputs/fig_pixel_mc.tex}


\section{Further Work}\label{sec:future}
So far we have generated the proposals randomly and do not take the current segmentation into account.

So far we only enforce must link constraints to obtain smaller problems.
One can also enforce cannot link constraints to the problem. 
If those are closed, they automatically lead to a decomposition of the problem, 
which is a interesting property for very huge data.

Improving proposals.




\section{Conclusion}\label{sec:conclusion}

We have presented a fast and scalable 
approximate solver for correlation 
clustering, named Fusion Moves for correlation clustering (FM-CC).
The best solution is iteratively improved 
by a fusion with proposal solutions.
The fusion move itself is formulated as correlation
clustering on a smaller graph fewer edges and nodes
and can therefore be solved very fast.
Our evaluation shows that CC-FF
significantly outperforms 
other solvers w.r.t. any time performance 
with increasing problem size.


    


\newpage

\FloatBarrier
{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

% \newpage

% \onecolumn
% \section{Appendix}

% \input{tables/anytime/image-seg.tex}
% \input{tables/anytime/knott-3d-150.tex}
% \input{tables/knott-3d-300.tex}
% \input{tables/anytime/knott-3d-450.tex}
% \input{tables/knott-3d-550.tex}
% \input{tables/anytime/seg-3d.tex}
% \input{tables/modularity-clustering.tex}



\end{document}
