\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{eso-pic}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{booktabs}


% Include other packages here, before hyperref.
\usepackage{my_macros}
\usepackage{paralist}
\usepackage{amsthm}
\usepackage{dirtytalk}
%\usepackage{framed}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{setspace}
%for tikz
\usepackage{tikz,pgfplots}
\usepackage{pgfplotstable}
\usepackage{filecontents}
\usetikzlibrary{arrows,positioning,automata,shadows,fit,shapes}
\usetikzlibrary{arrows,petri,topaths}
\usetikzlibrary{positioning,fit,calc}
\usetikzlibrary{shapes.arrows,chains,decorations.pathreplacing,fadings}
\usetikzlibrary{calc, matrix, backgrounds}

\pgfplotsset{every axis/.append style={
  every axis y label/.style = {at={(ticklabel cs:0.5)}, rotate=90, anchor=south},
  axis x line = {bottom},
  axis y line = {left},
  tick align = outside,
  ymajorgrids = true,
%  legend style = {draw=none, at={(1.05, 0.5)}, anchor=west, font=\small},
  legend style = {font=\tiny},
  legend columns = 1,
  every axis plot/.append style = {line width=1pt},
  label style = {font=\small},
  tick label style={font=\small},
  scaled ticks = false,
}}

%\usepackage{tkz-berge}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\definecolor{shadecolor}{rgb}{0.01,0.199,0.1}
\usepackage{xargs} 
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\usepackage{bm}% Ã¤ndert \boldsymbol
\def\arraystretch{0.8}
\renewcommand{\tabcolsep}{2pt}
\newcommand{\thickline}{2pt}
\newcommand{\scatterplotpath}{./scatterplots/}

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}
\newcommand{\OR}{\textrm{ or }}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}
%%%%%%%%% TITLE
\include{my_macros.tex}
%\title{Correlation Clustering with Dynamic Super-Nodes (DySNCC)}
\title{Fusion Moves for Correlation Clustering}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


\listoftodos[Notes]
%%%%%%%%% ABSTRACT
\begin{abstract}
   We address the problem of partitioning a  graph
   into a previously unknown number of clusters.
   Among all partitions, the one with the minimal 
   sum of of cut edge weights is chosen. 
   This problem is known as correlation clustering 
   or multicut.
   We propose a general framework to find
   high quality approximate solutions for 
   this NP-hard problem based on a move making algorithm:
   We use candidate solutions from a proposal generator
   to iteratively improve the best observed solution similar
   to fusion moves.
   The proposed solver outperforms any other solver
   w.r.t. to any time performance.
   The solutions found by this solver are close
   to global optimal solutions w.r.t. energy
   and problem specific measurements as VI for
   image segmentation problems.

\end{abstract}
\section{Introduction}


\paragraph{Our Notation}
$G$ Graph.
$V$ Set of Nodes.
$E$ Set of Edges.
$l$ node label.
$y$ edge label.
$w$ edge weight
$MC(G)$ multicut polytope
$P(G)$ the set of valid edge labeling (MC(G) is convex hull of P(G))
$y^*$ for opt. labeling
$G_y=(V_y,E_y)$ contradiction of graph $G$ with respect to $y$

%$\rho_y : E \to E_y$
%$\rho_y^{-1} : E_y \to E$

$\rho_y : P(G) \to P(G_y)$


$\rho_y^{-1} : P(G_y) \to P(G)$
\begin{itemize}
  \item Multicut in computer vision, applications, sparse segmentation -> IMPORTANT PROBLEM
  \item Problem: Existing Methods does not scale, even CGC. - Large scale 3d problems
  \item Contribution: Fast scalable method using novel fusion moves for correlation clustering
\end{itemize}



Given an edge weighted graph, positive weights (\emph{attractive})
encourage the adjacent nodes to be in the same 
connected component, while negative weights (\emph{repulsive}) encourage
the nodes to stay in different connect components.
Therefore the sign of the weights encodes if two
nodes should be merged or not and the magnitude of the weights encodes
the certainty of this desire.
The objective of correlation clustering / multicuts
is finding the cut with a minimal sum of cut edge weights.
The number of connected components / clusters is discovered
from the weights ( rewrite?!?).
Correlation clustering / the multicut is NP-hard \cite{???}.
%
Despite the NP-hardness, correlation clustering has been 
successfully used for
\begin{inparaenum}[(i)]
    \item partitioning a superpixel region adjacency graph~\cite{andres_2011_iccv,kroeger_2012_eccv}
    \item with optional long range repulsive edges~\cite{andres_2013_emmcvpr}.
    \item Alush and Globerger showed how to average multiple segmentations with the multicut objective~\cite{alush_2012_pami}.
    \item Multicuts can also be used for interactive segmentation~\cite{bagon_2011_arxiv},
    \item for co-segmentation~\cite{glassner_2011_cvpr}
    \item and to cluster sparse and graphs~\cite{???}.
\end{inparaenum}


Despite the nice properties of correlation clustering
to perform a \say{one-shot agglomeration of supervoxels} ~\cite{nunez_iglesias_2013},
the main draw back of correlation clustering is scalability~\cite{nunez_iglesias_2013}.
Existing solvers for correlation clustering do not scale for non planar graphs.
Even state of the art approximate move making algorithm fail 
to give good approximations non planar graphs.
When increasing the problem sizes, either the runtime explodes or the 
approximations are far away from being useful.


\textbf{Contribution:}
\begin{inparaenum}[(i)]
\item Within this work we propose a fast and scalable move making algorithm for correlation clustering,
\item which generalized  fusion moves \cite{???} to correlation clustering problems.
\item We reduce the inference to a series of moves where
each moves optimizes over a subspace spanned by the current best solution
and a proposal solution.
\item We propose two versatile proposal generators,
\item and show how to optimize these moves.
\item We give a polyhedral interpretation of this algorithm,
\item and evaluate the proposed method 
on existing benchmark problems.
\item We show state of the art any time performance on those instances.
\end{inparaenum}[(i)]

\textbf{Outline:}
In sec.~\ref{sec:problem_formulation} we will give a 
detailed problem definition where we introduce 
the correlation clustering objective.
In sec.~\ref{sec:related_work} we will 
discuss existing methods for correlation 
clustering and briefly explain the concept of fusion moves.
In sec: ~\ref{sec:cc_fm} we describe our proposed
method and show the properties of the algorithm.
In sec.~\ref{sec:exp} we show an evaluation
of the method on existing parameter  and discuss the effects of parameters.
Future work will be discussed in sec. \ref{sec:future} and
we will conclude in ~\ref{sec:conclusion}.
%-------------------------------------------------------------------------

\section{Problem Formulation}\label{sec:problem_formulation}
Def: Graph, weighted graph, cut, multicut 


\begin{center}
    \begin{eqnarray}
        l^* &=& \argmin_{L \in \{1,\ldots,|V|\}^{|V|}} \sum_{ (i,j) \in E } w_{ij} \cdot [l_{i} \neq l_{j}] \label{eq:nodeproblem}\\
   %     y_{ij}^* &=& [l_{u} \neq l_{v}] 
        y^* &=& \argmin_{y \in MC(G)\cap \{0,1\}^{|E|}} \sum_{ (i,j) \in E } w_{ij} \cdot y_{ij} \label{eq:edgeproblem}%\\ 
    \end{eqnarray}
\end{center}

The exist an surjective mapping from a node-label $l$ to edge-labeling $y$ and
a bijective mapping from a partitioning of $V$ to vertices of the multicut polytope $MC$.
Consequently, 
(i) problems \ref{eq:nodeproblem} and \ref{eq:edgeproblem} are equivalent
and (ii) the node-labeling is not unique for a given partitioning and introduce some
ambiguities.

% \subsubsection{Multicut Objective}

% The multicut / correlation clustering objective 
% can be formulated in different ways.



% \paragraph{Edge Indicator Variables:}
% \begin{center}
%     \begin{eqnarray}
%         y^* &=& \argmin_{y} \sum_{ e_{ij} \in E } w_{ij} \cdot y_{ij} \\
%         s.t.:& & y \in \textit{Multicut Polytope} \nonumber
%     \end{eqnarray}
% \end{center}

% \paragraph{Fully Connected Graph:}
% \begin{center}
%     \begin{eqnarray}
%         y^*   & = & \argmin_{y} \sum_{ i<j \in V } w_{ij} \cdot y_{ij} \\
%         s.t.: &  & y_{ij} + y_{jk} < y_{i,k} \quad \forall i, j, k   \nonumber
%     \end{eqnarray}
% \end{center}

% \paragraph{Node Coloring:}
% \begin{center}
%     \begin{eqnarray}
%         l^* &=& \argmin_{L} \sum_{ e_{ij} \in E } w_{ij} \cdot [l_{u} \neq l_{v}] \\
%         y_{ij}^* &=& [l_{u} \neq l_{v}]  
%     \end{eqnarray}
% \end{center}

\section{Related Work}\label{sec:related_work}

\subsection{Correlation Clustering}\label{sec:cc}
A major branch of research has focused on solving 
relaxations of eq.~\ref{eq:edgeproblem} by linear programming
or solving  eq.~\ref{eq:edgeproblem} directly to global optimality
by using integer linear programming in a cutting plane fashion  \cite{kappes_2011_emmcvpr,andres_2011_iccv}.


Yarkony et al ~\cite{yarkony_2012_eccv} uses 
a dual decomposition based approach for planar graphs
where the subproblems are planar max cut instances.

An other branch of research uses move making algorithm 
to optimize correlation clustering.
Bansal and Bagon use a modified $\alpha-$expansion \cite{bansal_2004_ml} 
algorithm suitable for correlation clustering,
while the state of the art method from  Beier \etal~\cite{beier_2014_cvpr} iteratively re-optimizes the cuts
between adjacent connected components.


   % \begin{itemize}
   % \item Multicut~\cite{kappes_2011_emmcvpr}
   % \item Expand and Explorer~\cite{bagon_2011_arxiv}
   % \item Fast Planar CC~\cite{yarkony_2012_eccv}
   % \item Break and Conquer \cite{alush_2013_simbad}.
   % \item Cut Glue And Cut~\cite{beier_2014_cvpr}
   % \end{itemize}

\subsection{Fusion Moves}\label{sec:fm}
Move making algorithms, in particular fusion moves, 
have become increasingly popular for energy minimization~\cite{???,kappes_2014_ws}.
For many large scale computer vision applications fusion moves lead to good approximations
with state of the art any time performance~\cite{kappes_2014_ws}.
The fusion move algorithm works as follows:
A current best solution is maintained and proposal solutions 
are generated.
Within each move, the variables can choose the label from the current best or from the 
proposed solution. This problem can be formulated as an 
optimization problem with a binary label space.
Any optimal solution of this auxiliary problem is guaranteed
to not worsen the current best solution.



% \subsection{Karger-Stein Algorithms}
% Use randomized procedure to reduce the number of nodes / edges to a reasonable 
% number.
% On the smaller graph, more expensive solvers are used.



%------------------------------------------------------------------------
\section{Correlation-Clustering-Fusion (CCF) Moves}\label{sec:cc_fm}
Motivation Using Fusion moves -> problem ambiguity


%\input{inputs/fig_alg_graph.tex}


\subsection{Define Fusion on Segmentations}

Given two proposal solutions $y'$ and $y''$
the fusion move between those solutions is defined
as follows:

Let the $\bar{y}$ be the edge wise or of  $y'$ and $y''$.
\begin{equation}
\breve{y} =  y' \cup y''.
\end{equation}
Contraction of all edges in $G$ where $\bar{y}=0$ defines
a smaller graph $G_{\bar{y}}$ and the corresponding
edge weights $W_{\hat{y}}$.
Any cut $\bar{y}$ on $G_{\hat{y}}$ induces a cut $y$ on $G$.
The function 
$\rho_y^{-1}$ maps a cut from $G_{\hat{y}}$  to $G$ 

\begin{equation}
   \rho_y^{-1} : P(G_y) \to P(G)
\end{equation}

Therefore solving eq. \ref{eq:edgeproblem} 
on $G_{\hat{y}}$
leads to a cut on $G$ which is guaranteed to 
to have a better or equal energy
then any of the two proposal solutions.

\input{inputs/fig_move_graph.tex}


% Global optimal solvers for multicut do not scale beyond ??? \cite{???}.
% Good approximate solvers for planar graphs exist \cite{beier_2014_cvpr,yarkony_2012_eccv} 
% but have difficulties to find good solutions for non planar graphs \cite{beier_2014_cvpr}.

% To make multicuts scalable, it is desirable to replace the graph $G$
% with a graph $\hat{G}$, which is smaller in the number of nodes and edges. 
% If $\hat{G}$ is small enough, it is feasible to use global optimal solvers.

% A trivial way to reduce the size of the graph  is edge contraction.
% Until a desirable size is reached, one might contract the edge with
% the highest weight. A cut on the contracted graph  $\hat{G}$ is always
% a valid cut on $\hat{G}$.

% On the other hand, if an edge $e$ is contracted, it will never be cut.
% If $e$ is part of the cut in a global optimal solution, we cannot find
% this cut.

% To overcome this problem  we can randomize the edge contraction,
% and repeat this multiple times and remember the best solution.

% But this would throw away all the ``not the best'' solutions (rewrite me).
% Within this work we propose the following nifty trick.
% Instead of throwing away solutions, we intersect them with the 
% best solution, and solve the multicut on the resulting
% graph.
% Therefore we fuse multiple solutions,



\begin{algorithm}
\begin{scriptsize}
\caption{Fusion Based Algorithms}\label{alg:fusion}




\begin{algorithmic}[1]
\Procedure{Intersection-Based-Inference}{GEN,$J$,$X$}
\State $x^0 \gets \textrm{initial state form } X$
\State $n \gets 0 $                                 \Comment{Number of moves}
\State $m \gets 0 $                                 \Comment{Number of moves without progress}
\While{$m < m_{\max}$ and $n < n_{\max}$ }
\State $n \gets n+1$ 
 \State $x'\gets GEN(x^{n-1},J,X)$                    \Comment{Generate proposal}
 \If{$J(x^{n-1}) \leq J(x')$}                       
   \State $x^{n} \gets Fuse(x^{n-1},x',J)$             
 \Else
   \State $x^{n} \gets Fuse(x',x^{n-1},J)$
 \EndIf
 \If{$J(x^{n}) \leq J(x^{n-1})$}
   \State $m \gets 0$                                 \Comment{Reset counter}
 \Else
   \State $m \gets m+1$                               \Comment{Increment counter}
 \EndIf
\EndWhile
\State \textbf{return} $x^n$
\EndProcedure
\end{algorithmic}
\end{scriptsize}
\end{algorithm}




\begin{algorithm}
\begin{scriptsize}
\caption{Fusion Moves}\label{alg:fusion_moves}
\scriptsize
\begin{algorithmic}[1]
\Require $J(x) \leq J(x')$
\Ensure $J(\hat{x}) \leq J(x)$
\vspace{0.2cm}
\Procedure{Fuse}{$x,x',J$}
\State $\bar{x} \gets \textbf{\scriptsize{Intersect}}(x,x')$  
    \Comment{
        \begin{minipage}{0.4\linewidth} 
            \begin{tiny}
            \begin{singlespace}
                intersect
                uncut edges in $x$ and $x'$,
                return  
                connected component labeling
            \end{singlespace}
            \end{tiny}
        \end{minipage}
    }
\vspace{0.1cm}
\State $ \tilde{G}=(\tilde{E},\tilde{V}),\tilde{W} 
    \gets \textbf{\scriptsize{Contract}}(G,W,\bar{x})$  
    \Comment{ 
        \begin{minipage}{0.2\linewidth} 
            \begin{tiny}
            \begin{singlespace}
                Contract all edges 
                which are uncut in $\bar{x}$ 
            \end{singlespace}
            \end{tiny}
        \end{minipage}
    }
\vspace{0.1cm}
\State $\tilde{x}^*= \argmin\limits_{\tilde{x}} \sum\limits_{e_{ij} \in \tilde{E}} \tilde{w}_{ij}[\tilde{x}_i \neq \tilde{x}_j]$
    \Comment{ 
        \begin{minipage}{0.3\linewidth} 
            \begin{tiny}
            \begin{singlespace}
                Solve the multicut objective
                on smaller graph $\tilde{G}=(\tilde{V},\tilde{E})$
            \end{singlespace}
            \end{tiny}
        \end{minipage}
    }

\State $\hat{x} \gets \textbf{\scriptsize{ProjectBack}}(\tilde{x}^*)$
    \Comment{ 
        \begin{minipage}[\textheight]{0.4\linewidth} 
            \begin{tiny}
            \begin{singlespace}
                Translate the connected component
                labeling $\tilde{x}^*$ of $\tilde{G}$ 
                to a connected component labeling of $G$
            \end{singlespace}
            \end{tiny}
        \end{minipage}
    }
\State \textbf{return} $\hat{x}$
\EndProcedure
\vspace{0.3cm}
\Procedure{FUSE$_{\textrm{BASE}}$}{$x,x',J$}
\State \textbf{return} ${\arg\min}_{\bar{x} \in \{x,x'\}}J(\bar{x})$
\EndProcedure
\end{algorithmic}
\end{scriptsize}
\end{algorithm}






%-------------------------------------------------------------------------
\subsection{Fusion Move Solver}




\begin{center}
    \begin{eqnarray}
        y 
        &=& 
        \rho_{\hat{y}}^{-1}(
        \argmin_{y \in MC(G_{\hat{y}})\cap \{0,1\}^{|E_{\hat{y}}|}} 
        \sum_{ (i,j) \in E_{\hat{y}} } 
        w^{\hat{y}}_{ij} \cdot \bar{y}_{ij} 
    \end{eqnarray}
\end{center}

\begin{center}
    \begin{eqnarray}
      y \cdot w \leq \min(y'\cdot w,  y'' \cdot w) 
    \end{eqnarray}
\end{center}


%-------------------------------------------------------------------------
\subsection{Proposal Generators}

\textbf{Desired Properties}




\begin{algorithm}
    \begin{scriptsize}
        \caption{Proposal Generators}\label{alg:proposal_gen}   
        \begin{algorithmic}[1]
            %\Require $J(x) \leq J(x')$
            %\Ensure $J(\hat{x}) \leq J(x)$
            %\vspace{0.3cm}
            \Procedure{Rand2Coloring}{$x,G=(E,V),W$}
            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
            \State $x'= \argmin\limits_{\bar{x}} \sum\limits_{e_{ij} \in E } \tilde{w}_{ij}[\bar{x}_i \neq \bar{x}_j]  [x_i = x_j]   $

            $ \quad\quad s.t.\quad x_i \in \{0, 1\} \forall i $
            \State \textbf{return} $x'$
            \EndProcedure
            %
            %
            \vspace{0.3cm}
            \Procedure{RandEdgeWeightedWatersheds}{$x,G=(E,V),W$}
            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
            \State $ getRandomSeeds$
            \State $ runEdgeWeightedWs$
            \EndProcedure   
            %
            %
            \vspace{0.3cm}
            \Procedure{RandHierarchicalClustering}{$x,G=(E,V),W$}
            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
            \State $\hat{G}=(\hat{E},\hat{V}) \gets G=(E,V)$
            \State $\hat{W} \gets W$
            \While{$|\hat{V}|>\gamma$ \textbf{and}  $\max(\hat{W})>\theta$ }
                \State $\hat{G}=(\hat{E},\hat{V}),\hat{W} \gets 
                    \textbf{\scriptsize{contract}}(\hat{G},\hat{W},  \argmax\limits_{\hat{E}}(\hat{W}) )$
            \EndWhile
            \State $x' \gets \textbf{\scriptsize{getClusterResults}}(???) $ 
            \EndProcedure
        \end{algorithmic}
    \end{scriptsize}
\end{algorithm}



\subsubsection{Randomized HierarchicalClustering (RHC)}

To generate proposals cut we can use bottom up hierarchical clustering.
In each step we contract the edge with the highest weight.
Parallel edges are merged into single edges by summing their weights.
We stop when a certain number of nodes is reached, or the
largest edge weight among the not yet contracted edges is smaller then a certain threshold.
To get versatile proposals we either add noise 
to the edge weighs or permute a certain number of weights.


\subsubsection{Randomized MaxCut  (RMC)}

To get energy aware proposals we can use max cuts.
The max cut objective is the same as
the multicut objective, but only two 
node colors are allowed.
Therefore solutions of the max cut objective
might be useful proposals.
To create different proposals we set 
the weight of edges which are cut 
in the best solution to zero.
In this way we favor solutions 
different form the current best. 
In addition we either add noise permute a certain number of weights.


\subsubsection{Randomized Watersheds (RWS)}

The edge weighted watershed algorithm \cite{meyer_2013}
with random seeds can be used to get 
cheap proposals. Instead of $n$ seeds distributed uniformly
over all nodes we use the following.
Draw $n/k$ random edges only the negative edges, 
and give the two nodes of each random edge different seeds.
Doing so, a random subset of negative edges is forced
to be cut within each proposal.
For additional randomness, noise can be added to
the edge weighs.



\input{inputs/fig_hc.tex}

\subsection{Properties and Polyhedral Interpretation}
An alternative interpretation of our method is shown in Fig.~\ref{fig:polyheadral}.
In each iteration the current and proposed segmentation define an inner polyheadral 
approximation of the original multicut polytope. 
Optimizing over this polytope is the same problem as the original one, but much smaller.
Furthermore, the costs does not change and and improvement in the smaller polytope will 
be the same in the original graph.
The choice of the proposal defines the shape of the auxiliary polytope. 
In the given toy example, the first (red) polytope give a huge improvement, the second proposal
defines the blue polytope which does not lead to an improvement. 
The third proposal generates the green polytope that includes the global optimal solution.

This procedure is fundamental different to common polyhedral multicut methods~\cite{kappes_2011_emmcvpr,kappes_2013_arxiv}, 
which tighten a outer relaxation of the multicut polytope and contrary to our method do not operate in the feasible domain. 



\begin{figure}
\centering
\input{polytope-tikz.tex}
\caption{Each move can be interpreted as an optimization of an inner polyhedral optimization.
Each polyhedral approximation includes the current vertex. Starting with $y_0$ we optimize over the red polytope 
and find $y_1$ as optima. When optimize over the blue polytope we stay in $y_1$ as optima.
When optimizing over the green polytope we find $y_2$ which we will never leaf again or any polytope containing $y_2$. 
}
\label{fig:polyheadral}
\end{figure}


\begin{theorem}[Equivalence]
The optimal multicut $\bar{y}^*$ on the contracted graph $G_y$
is equivalent to the optimal multicut $y^*$ in the original graph $G$ 
with additional must link constraints ($y^* \leq y$).
%
\begin{proof}
Since $y^*$ fulfills all  must link constraints, we have  $y^*\cdot w = \rho^{-1}_y(y^*)\cdot \bar{w}$.
Consequently, $y^*\cdot w = \rho_y(\bar{y}) \cdot w$ and  $\rho^{-1}_y(y^*)\cdot \bar{w}= \bar{y}\cdot\bar{w}$.
\end{proof}
%
\end{theorem}




\begin{theorem}[Monotone]
Let $y'$ and $y''$ be two proposal solutions and  $y^*$ the optimal fused segmentation.
Than $y^*$  will never decrease the energy:
$y^* \cdot w \leq  \min( y'\cdot w,  y''\cdot w) $ 
%
\begin{proof}
The feasible set of the fusion move includes per definition  $y'$ and $y''$.
If $y'$ or $y''$ would have lower multicut cost than $y^*$, $y^*$ would not be optimal 
and that why not the propose segmentation of a fusion.
\end{proof}
%
\end{theorem}


\begin{remark}[Fix-point (pointless to me)]
Let $Y$ be the set of possible proposals, than
$y'$ is a fix-point if $y'=\arg\max_{y\in P(G_{y'\OR y''})} y\cdot w$ for all $y''\in Y$
\end{remark}



\begin{remark}[Optimality]
Let $y'$ be the current and $y''$ the proposed segmentation.
If the optimal solution $y^*$ lies in $P(G_{y' \OR y''})$ than a optimal fusion move will return $y^*$.
\end{remark}



\section{Experiments}\label{sec:exp}

\subsection{Parameter Choice}
\begin{figure}
\centering
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-time.pdf}}
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-value.pdf}}
\caption{Empirical evaluation of the impact of noise used for proposal generation and proposal size.
  Proposals with many segments causes longer runtime. Noise seemed not to be a critical parameter but should be selected large enough.
}
\end{figure}

\subsection{Synthetic Models}

\subsection{Social Networks}
A application for large scale correlation clustering are social networks.
We consider two of those networks from the Stanford Large Network Dataset Collection\footnote{http://snap.stanford.edu/data/index.html}.
Both networks are given by weighted directed graphs with edge weights $-1$ and $1$. 
%
The first network is called \emph{Epinions}. 
This is who-trust-whom online social network of a a general consumer review site Epinions.com. 
Each directed edge $a\to b$ indicated that user $a$ trusts  or does not trust user $b$ is the edge-weight is positive or negative, respectively.
The network contains $131828$ nodes and $841372$ edges from which $85.3\%$ are positively weighted.
%
The first network is called \emph{Slashdot}. 
Slashdot is a technology-related news website know for its specific user community. 
In 2002 Slashdot introduced the Slashdot Zoo feature which allows users to tag each other as friends or foes. 
The network was obtained in November 2008 and contains $77350$ nodes and $516575$ edges from which $76.73\%$ are positively weighted.

We consider the problem to cluster this graphs such that positively weighted edges link inside and negatively weighted between clusters.
In other words friends and people who trust each other should be in the same segment and foes and non-trusting people in different clusters.
% 
To compensate the high impact of nodes with high degree we can normalize the edge weights such that each person has the same impact to the overall network, by enforcing.
\begin{align}
  \sum_{i\to j \in E_{\to}} |w_{i\to j}| &= 1&\forall i\in V, deg^{\textrm{out}}(i)\geq 1 
\end{align}
We define the following energy function
\begin{align}
 J(y) &= \sum_{i\to j \in E^+_{\to}} y_{ij}\cdot w_{i \to j} +  \sum_{i\to j \in E^-_{\to}} (y_{ij}-1)\cdot w_{i \to j} \nonumber\\
      &= \sum_{ij \in E} y_{ij}\cdot \underbrace{(w_{i \to j}+w_{j \to i})}_{w_{ij}} + \textrm{const}
\end{align}
which is zero if the given partitioning does not violated any relation and larger otherwise.


\subsection{Real World Models}
An example for large scale correlation clustering is 
segmentation of region adjacency graphs (RAG) for
3D closed surface segmentation of neural tissue data 
\cite{kroeger_2012_eccv}.
The energy is based on a likelihood of merging adjacent super-voxels.
Each edge has a probability to keep adjacent segments separate ($p(y_{ij} =1)$)
or to merge them ($p(y_{ij} = 0)$).
The energy function is defined as following.
\begin{align}
 J(y)  &= \sum_{ij \in E} y_{ij}\cdot \underbrace{  log\left( \frac{p(y_{ij} =0)}{p(y_{ij} =1)}\right) + log \frac{1-\beta}{\beta}  }_{w_{ij}}
\end{align}
Where $\beta$ is used as a prior.
Models of different size are included in the graphical model
benchmark of Kappes \etal ~\cite{kappes_2013_benchmark_cvpr} (???).
We use models with the cube sizes $300^3$, $450^3$, $550^3$ and $900^3$.
The number of variables varies from ??? to ???, and the number
of edges from ??? to ???.

\begin{center}
    \begin{figure}
        \begin{center}
            \begin{subfigure}[b]{0.45\linewidth}
                \includegraphics[width=1.0\linewidth]{images/-010.jpg}
            \end{subfigure}
            \quad
            \begin{subfigure}[b]{0.45\linewidth}
                \includegraphics[width=1.0\linewidth]{images/-030.jpg}
            \end{subfigure}
        \end{center}
    \caption{
        Raw FIBSEM data and correlation clustering result of the model from \cite{kroeger_2012_eccv}
    }
    \end{figure}
\end{center}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
restrict y to domain=0:4600,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
%\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/knott-3d-150.data};
%\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC-planar]{data/image-seg.data};
\addlegendentry{CGC-planar} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/image-seg.data};
\addlegendentry{MCI-CCIFD} 

\addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC-CGC]{data/image-seg.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/image-seg.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{image-seg}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
restrict y to domain=-6000:-4500,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
%\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/knott-3d-150.data};
%\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC]{data/knott-3d-150.data};
\addlegendentry{CGC} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/knott-3d-150.data};
\addlegendentry{MCI-CCIFD} 

\addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC-CGC]{data/knott-3d-150.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/knott-3d-150.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{knott-3d-150}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
restrict y to domain=-40000:-24000,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/knott-3d-300.data};
\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC]{data/knott-3d-300.data};
\addlegendentry{CGC} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/knott-3d-300.data};
\addlegendentry{MCI-CCIFD} 

\addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC-CGC]{data/knott-3d-300.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/knott-3d-300.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{knott-3d-300}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
restrict y to domain=-80000:-60000,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/knott-3d-450.data};
\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC]{data/knott-3d-450.data};
\addlegendentry{CGC} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/knott-3d-450.data};
\addlegendentry{MCI-CCIFD} 

\addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC-CGC]{data/knott-3d-450.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/knott-3d-450.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{knott-3d-450}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
restrict y to domain=-10000000:-100000,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/knott-3d-550.data};
\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC]{data/knott-3d-550.data};
\addlegendentry{CGC} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/knott-3d-550.data};
\addlegendentry{MCI-CCIFD} 

\addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC-CGC]{data/knott-3d-550.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/knott-3d-550.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{knott-3d-550}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\begin{figure}[H]
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{semilogxaxis}[
%restrict y to domain=-10000000:-100000,
restrict y to domain=-10000000:700000,
xlabel = {runtime},
xmin = 0,
xmax = 4100,
%ymin =  75282844.25,
%ymax =  81774642.015,
%xtick       = { 1 , 60 , 3600 },
%xticklabels = { 1 sec. , 1 min.  , 1 hour },
%ytick       = {75661636, 78718140, 81774643 },
%yticklabels = {$75661636$, $78718140$, $81774643$ },
width = 0.9\columnwidth,
scaled ticks = false
]
\addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data/seg-3d.data};
\addlegendentry{HC-CGC}

\addplot[color=red,mark=x] table[x=time,y=CGC]{data/seg-3d.data};
\addlegendentry{CGC} 

\addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data/seg-3d.data};
\addlegendentry{MCI-CCIFD} 

%\addplot[color=yellow,mark=o] table[x=time, y=DYNCC-HC-MC]{data/seg-3d.data};
%\addlegendentry{MC-Fusion (HC-MC)}

\addplot[color=green,mark=o] table[x=time, y=DYNCC-HC-MC-CGC]{data/seg-3d.data};
\addlegendentry{MC-Fusion (HC-MC-CGC)}

\addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC-CGC]{data/seg-3d.data};
\addlegendentry{MC-Fusion (HC-CGC-CGC)}

\end{semilogxaxis}
\end{tikzpicture}
\caption{seg-3d}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{figure}
\input{scatterplots/knott-3d-450.tex}
\caption{Values and runtime for the 8 knott-3d-450 instances. Note that we use for DYNCC a defensive stopping condition.
A more aggressive one would lead to much faster runtime with only a bit worse values.
DYNCC find solutions with less than distance 100 to the optimum a magnitude faster than the state of the art, which produce poor results on hard instances with a 1 hour time limit.
}
\end{figure}



%\subsection{Pixel-wise Multicuts}
%\input{inputs/fig_pixel_mc.tex}


\section{Further Work}\label{sec:future}
So far we have generated the proposals randomly and do not take the current segmentation into account.

So far we only enforce must link constraints to obtain smaller problems.
One can also enforce must-not link constraints to the problem. 
If those are closed, they automatically lead to a decomposition of the problem, which is a interesting property for very huge data.


\section{Conclusion}\label{sec:conclusion}

    


\newpage
{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\newpage
\onecolumn
\section{Appendix}

\input{tables/anytime/image-seg.tex}
\input{tables/anytime/knott-3d-150.tex}
\input{tables/knott-3d-300.tex}
\input{tables/anytime/knott-3d-450.tex}
\input{tables/knott-3d-550.tex}
\input{tables/anytime/seg-3d.tex}
\input{tables/modularity-clustering.tex}



\end{document}
