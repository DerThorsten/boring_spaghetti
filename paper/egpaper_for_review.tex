\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{eso-pic}
\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{placeins}


% Include other packages here, before hyperref.
\usepackage{my_macros}
\usepackage{paralist}
\usepackage{amsthm}
% \usepackage{dirtytalk} fah: my miktex didn't like this; and we don't need it here. 
%\usepackage{framed}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{setspace}
%for tikz
\usepackage{tikz,pgfplots}
\usepackage{pgfplotstable}
\usepackage{filecontents}


%\usepackage{scrextend}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
% \pdfpageattr{/Group <</S /Transparency /I true /CS /DeviceRGB>>}
% \usepackage{everypage}
% \AddEverypageHook{%
%   \makeatletter%
%   \special{pdf: put @thispage <</Group << /S /Transparency /I true /CS /DeviceRGB>> >>}%
%   \makeatother%
% }%

\newcommand{\footlabel}[2]{%
    \addtocounter{footnote}{1}%
    \footnotetext[\thefootnote]{%
        \addtocounter{footnote}{-1}%
        \refstepcounter{footnote}\label{#1}%
        #2%
    }%
    $^{\ref{#1}}$%
}

\newcommand{\footref}[1]{%
    $^{\ref{#1}}$%
}
\usetikzlibrary{arrows,positioning,automata,shadows,fit,shapes}
\usetikzlibrary{arrows,petri,topaths}
\usetikzlibrary{positioning,fit,calc}
\usetikzlibrary{shapes.arrows,chains,decorations.pathreplacing,fadings}
\usetikzlibrary{calc, matrix, backgrounds}




%%%%%%global tikz styles
\tikzstyle{nS}=[circle,minimum size = 0.6cm,inner sep = 0pt,draw, font=\small,align=left]
\tikzstyle{eNS}=[fill=white,minimum size = 0.5cm,inner sep = 0pt, font=\tiny,align=left]

\tikzstyle{eBlack}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=black!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eNotCut}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=green!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eBlue}=[very thick,minimum size = 0.5cm,inner sep = 0pt,draw=blue!70!black, font=\small,align=left, line width=1mm]
\tikzstyle{eCut}=[very thick,dotted,minimum size = 0.5cm,inner sep = 0pt,draw=black, font=\small,align=left, draw=red!70!black, line width=1mm]

\pgfplotsset{every axis/.append style={
  every axis y label/.style = {at={(ticklabel cs:0.5)}, rotate=90, anchor=south},
  axis x line = {bottom},
  axis y line = {left},
  tick align = outside,
  ymajorgrids = true,
%  legend style = {draw=none, at={(1.05, 0.5)}, anchor=west, font=\small},
  legend style = {font=\tiny},
  legend columns = 1,
  every axis plot/.append style = {line width=1pt},
  label style = {font=\small},
  tick label style={font=\small},
  scaled ticks = false,
}}

% Two Colored Circle Split 
\makeatletter
\tikzset{circle split part fill/.style  args={#1,#2}{%
 alias=tmp@name, 
  postaction={%
    insert path={
     \pgfextra{% 
     \pgfpointdiff{\pgfpointanchor{\pgf@node@name}{center}}%
                  {\pgfpointanchor{\pgf@node@name}{east}}%            
     \pgfmathsetmacro\insiderad{\pgf@x}
      \fill[#1] (\pgf@node@name.base) ([xshift=-\pgflinewidth]\pgf@node@name.east) arc
                          (0:180:\insiderad-\pgflinewidth)--cycle;
      \fill[#2] (\pgf@node@name.base) ([xshift=\pgflinewidth]\pgf@node@name.west)  arc
                           (180:360:\insiderad-\pgflinewidth)--cycle;            
         }}}}}  
 \makeatother  

%\usepackage{tkz-berge}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\definecolor{shadecolor}{rgb}{0.01,0.199,0.1}
\usepackage{xargs} 
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage{bm}% Ã¤ndert \boldsymbol
\def\arraystretch{0.8}
\renewcommand{\tabcolsep}{2pt}
\newcommand{\thickline}{2pt}
\newcommand{\scatterplotpath}{./scatterplots/}
\newcommand{\rd}{\color{red}}

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}
\newcommand{\OR}{\textrm{ or }}

% \cvprfinalcopy % *** Uncomment this line for the final submission


\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand{\realplot}[1]{
\begin{tikzpicture}
    \begin{axis}
        \addlegendimage{empty legend}\addlegendentry{Matrix #1}
        \addplot {0};
        \addplot {1};
        \addplot {2};
        \addplot {3};
    \end{axis}
\end{tikzpicture}}  

% \newcommand{\anytimeplot}[1]{
%   \addplot[color=brown,mark=x] table[x=time,y=HC]{data3/knott-3d-300.data};              \addlegendentry{HC}
%   \addplot[color=black,mark=x] table[x=time,y=HC-CGC]{data3/knott-3d-300.data};          \addlegendentry{HC-CGC}
%   \addplot[color=red,mark=x] table[x=time,y=CGC]{data3/knott-3d-300.data};               \addlegendentry{CGC}
%   \addplot[color=gray,mark=o] table[x=time, y=ogm-KL]{data3/knott-3d-300.data};          \addlegendentry{KL}
%   \addplot[color=purple,mark=x] table[x=time, y=MCR-CCFDB]{data3/knott-3d-300.data};     \addlegendentry{MC-R}
%   \addplot[color=blue,mark=x] table[x=time, y=MCI-CCIFD]{data3/knott-3d-300.data};       \addlegendentry{MC-I}
%   \addplot[color=green,mark=x] table[x=time, y=DYNCC-HC-MC]{data3/knott-3d-300.data};    \addlegendentry{Fusion-HC-MC}
%   \addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC]{data3/knott-3d-300.data};    \addlegendentry{Fusion-HC-CGC}
%   \addplot[color=orange,mark=x] table[x=time, y=DYNCC-WS-MC]{data3/knott-3d-300.data};  \addlegendentry{Fusion-WS-MC}
%   \addplot[color=orange,mark=x] table[x=time, y=DYNCC-WS-CGC]{data3/knott-3d-300.data};  \addlegendentry{Fusion-WS-CGC}
% }
\newcommand{\anytimeplot}[1]{
  \addplot[color=brown,mark=x] table[x=time,y=HC]{data3/#1.data};              \addlegendentry{HC}
  \addplot[color=black,mark=square] table[x=time,y=HC-CGC]{data3/#1.data};          \addlegendentry{HC-CGC}
  \addplot[color=red,mark=x] table[x=time,y=CGC]{data3/#1.data};               \addlegendentry{CGC}
  \addplot[color=gray,mark=o] table[x=time, y=ogm-KL]{data3/#1.data};          \addlegendentry{KL} 
  \addplot[color=yellow!50!black,mark=square] table[x=time, y=ogm-mcfusion-HC-CF*]{data3/#1.data};  \addlegendentry{Fusion}
  \addplot[color=purple,mark=o] table[x=time, y=MCR-CCFDB]{data3/#1.data};     \addlegendentry{MC-R}
  \addplot[color=blue,mark=o] table[x=time, y=MCI-CCIFD]{data3/#1.data};       \addlegendentry{MC-I}
  \addplot[color=green,mark=o] table[x=time, y=DYNCC-HC-MC]{data3/#1.data};    \addlegendentry{CC-Fusion-HC-MC}
  \addplot[color=cyan,mark=x] table[x=time, y=DYNCC-HC-CGC]{data3/#1.data};    \addlegendentry{CC-Fusion-HC-CGC}
  \addplot[color=orange,mark=o] table[x=time, y=DYNCC-WS-MC]{data3/#1.data};  \addlegendentry{CC-Fusion-WS-MC}
  \addplot[color=pink,mark=x] table[x=time, y=DYNCC-WS-CGC]{data3/#1.data};  \addlegendentry{CC-Fusion-WS-CGC}
}
%  \addplot[color=yellow!50!black,mark=o] table[x=time, y=ogm-mcfusion-HC-CF*]{data3/#1.data};  \addlegendentry{Fusion}
  %\addplot[color=green!50,mark=o] table[x=time, y=PIVOT*]{data3/#1.data};          \addlegendentry{PIVOT-BOEM}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi
\begin{document}
%%%%%%%%% TITLE
\include{my_macros.tex}
%\title{Correlation Clustering with Dynamic Super-Nodes (DySNCC)}
\title{Fusion Moves for Correlation Clustering}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
\input{abstract-new.tex}
%   \color{red} \textbf{TODO:}
% Correlation clustering, or multicut partitioning, is the NP-hard problem of partitioning an undirected graph or image with positive / attractive and negative / repulsive edge weights such that the sum of cut edge weights is minimized. We here present a move-making heuristic that uses cheaply generated proposal clusterings to iteratively and monotonously improve upon the best previously found clustering. A valid partitioning is maintained at all times, and solutions close to the global optimum are obtained faster than with any published technique. 
%    
%We address the problem of partitioning a  graph
%   into a previously unknown number of clusters.
%   Among all partitions, the one with the minimal 
%   sum of of cut edge weights is chosen. 
%   This problem is known as correlation clustering 
%   or multicut.
%   We propose a general framework to find
%   high quality approximate solutions for 
%   this NP-hard problem based on a move making algorithm:
%   We use candidate solutions from a proposal generator
%   to iteratively improve the best observed solution similar
%   to fusion moves.
%   The proposed solver outperforms any other solver
%   w.r.t. to any time performance.
%   The solutions found by this solver are close
%   to global optimal solutions w.r.t. energy
%   and problem specific measurements as VI for
%   image segmentation problems.
%
\end{abstract}
\vspace{-0.5cm}

\input{introduction-new.tex}
%\input{introduction-old.tex}
%\input{introduction-fred.tex}

\input{inputs/fig_hc_alg.tex}
\section{Energy Based Hierarchical Clustering}\label{sec:ehc}
Agglomerative hierarchical clustering (HC) is widely used
in graph / image segmentation~\cite{arbelaez_2006}.
In each step, the edge with the highest weight $w$ is
contracted (green edges in Fig.~\ref{fig:hc_alg}).
Doing so, parallel edges edges can occur.
In agglomerative clustering, weights of
parallel edges are merged into single edges.
For image segmentation, the length
weighted mean is used to do this update~\cite{arbelaez_2006}.

Because we, contrary to~\cite{arbelaez_2006}, directly work on energies, we are interested in an 
agglomeration with respect to our energy function~\ref{eq:edgeproblem}.
For this we propose to use energy based agglomeration
with the following update rule:
Whenever there are multiple edges between 
a pair of nodes, these edges are merged into a single edge
and the weights are summed up, since we 
minimize the sum of the cut edges.
We call HC with this update method Energy based Hierarchical Clustering (EHC).

We stop EHC if the highest edge weight is
smaller or equal to zero  (blue edge in Fig.~\ref{fig:hc_alg}). Any further edge
contraction does not improve the energies.

% Hierarchical clustering is fast, and 
% due to the agglomeration of edge weights, 
% {\color{red} hierarchical clustering is robust against noise}.
% {\color{yellow} [ First most similar nodes are merged...]
% In agglomerative clustering, weights of
% parallel edges are merged into single edges.}
% For image segmentation, the length
% weighted mean is used to do this update [ref].

% [We contrary on those works work directly on energy functions and that why ...]
% We propose to use Energy Based Hierarchical Clustering (EHC) to find
% solutions for correlation clustering.


% To make EHC follow the energy, we propose 
% the following update rule:
% Whenever there are multiple edges between 
% a pair of nodes, these edges are merged into a single edge
% by summing up their weights, since we 
% minimize the sum of the cut edges.
% The algorithm stops if the highest edge weight is
% smaller or equal to zero  (green edge in fig. ~\ref{fig:hc_alg}). Any further edge
% contraction leads to worse energies.

Given the intrinsic greediness of hierarchical clustering, 
EHC is sensitive against noise and we cannot expect optimal solutions.

But EHC is very fast, and can be used to initialize
CGC~\cite{beier_2014_cvpr}. Excessive time in CGC
is spend in the \emph{cut phase} to solve the 
first two coloring on the complete graph.
As shown in Sec.~\ref{sec:exp},
allowing CGC to start from the EHC solution
can improve performance drastically.



% Common cluster distances
% \begin{itemize}
% \item Single-Link: Nearest Neighbor - their closest members.
% \item Complete-Link: Furthest Neighbor - their furthest members.
% \item Centroid: Distance between centroids
% \item Group Average: average of all cross-cluster pairs.
% \end{itemize}



%------------------------------------------------------------------------
\section{Correlation Clustering Fusion Moves}\label{sec:cc_fm}

Fusion moves as defined in~\cite{Lempitsky-2010} work
in the node domain and do not work properly for 
objective functions as Eq.~\ref{eq:nodeproblem} since
the node coloring is ambiguous and has no semantic meaning, \cf Fig.~\ref{fig:fusion_abiguty}.
In the following, we propose a more suitable fusion move for correlation
clustering which works on the edge domain.
%
Given two proposal solutions $y'$ and $y''$,
$\mathcal{E}_0^{\breve{y}}$ is the set of edges
which are uncut in $y'$ and $y''$.
%
\begin{align}
\breve{y}_{ij}    & = \max\{ y_{ij}', y_{ij}''\}  & \forall {ij}\in E\\  % y' \cup y'' \\
\mathcal{E}_0^{\breve{y}}  & =  \{ ij \in E \; | \; \breve{y}_{ij} = 0 \}
\end{align}
%
The fusion move for correlation clustering is solving Eq.~\ref{eq:edgeproblem}
with additional \emph{must-link constraints} for all edges in $\mathcal{E}_0^{\breve{y}}$.
%
\begin{align}
  y^* &= \argmin_{y \in P(G)} \sum_{ (i,j) \in E } w_{ij} \cdot y_{ij} \label{eq:fusion_move_a}.\\ 
      &\quad \textrm{s.t.} \quad y_{ij} = 0 & \forall (i, j) \in \mathcal{E}_0^{\breve{y}} \nonumber
\end{align}
%
By construction, solving Eq.~\ref{eq:fusion_move_a} cannot increase the energy w.r.t. the proposal
$y'$ and $y''$,
because $y'$ and $y''$ are feasible solutions for problem~\ref{eq:fusion_move_a}.
%\begin{align}
%  \sum  w_{ij} \cdot y^*_{ij}  \leq \min \left( \sum  w_{ij} \cdot y'_{ij} ,  \sum   w_{ij} \cdot y''_{ij} \right)
%\end{align}
%


%Once we know how to fuse segmentations, the actual algorithm 
%for correlation clustering 
%is simple and similar to the fusion move algorithm of 
As Lempitsky \etal~\cite{Lempitsky-2010}, 
we iteratively improve the best solution by
fusing it with proposal solutions.
The inherent difference is how we define the fusion.
%We fuse the segmentations according to Eq.~\ref{eq:fusion_move_a}.

As classical fusion, CC-Fusion does not provide a lower bound on the objective and 
has no sound stopping condition.
For latter we use a maximal number of iterations and maximal number of iteration without improvement as stopping condition.

A further difference is how we efficiently calculate the correlation clustering fusion move and how we generate proposals.
Both will be discussed next. The overall framework is sketched in Fig.~\ref{fig:move_graph}.


\input{inputs/fig_fusion.tex}

%\textbf{old}
%
%Motivation Using Fusion moves -> problem ambiguity
%
%A consistent edge labeling $y$ defines a segmentation of $V$ by enumerating the connected components 
%in $G|_y=(V,\{e\in E|y_e=0\}$ by $l_v = \#(v)$, where $\#(v)$ denotes the number of the connected component of the %node $v\in V$.
%
%We define the contradiction of graph $G_y=(V_y,E_y)$
%with $V_y=\{\#(v)|v\in V\}$ and $E_y=\{\#(v),\#(u)|uv\in E, y_{uv}=1\})$.

%\input{inputs/fig_alg_graph.tex}


\subsection{Fast Optimization of CC-Fusion Moves} \label{sec:fast_optimization}
In general the auxiliary fusion problem~\ref{eq:fusion_move_a} is, as for classical fusion~\cite{Lempitsky-2010}, NP-hard.
However, many variables have been fixed to be zero and we can reformulate~\ref{eq:fusion_move_a}
into a correlation clustering problem on a coarser graph, where all nodes which are connected
via must-link constraints are merged into single nodes. We call this graph \emph{contracted graph}.
%
\begin{definition}\emph{(Contracted Graph)}
Given a weighted graph $G=(V,E,w)$ and a segmentation of $G$ given by $y\in P(G)$,
we define the contraction of graph $G_y=(V_y,E_y, \bar{w})$
by $V_y=\{l_v(y)|v\in V\}$, $E_y=\{l_u(y)l_v(y)|uv\in E\}$, and 
$\forall \bar{u}\bar{v}\in E_y: \bar{w}_{\bar{u}\bar{v}}=\sum_{uv\in E, l_u(y)=\bar{u},l_v(y)=\bar{v}}w_{uv}$ 
\end{definition}
%
Any clustering $\bar{y}$ of the contracted graph $G_y=(V_y,E_y)$ can be \emph{back projected} to a clustering $\tilde{y}$ the original graph $G=(V,E)$ by
%
\begin{align}
\tilde{y}_{uv}&=\left\{ 
\begin{array}{ll}
\bar{y}_{l_u(y)l_v(y)}& \textrm{ if }l_u(y) \neq l_v(y)\\
0                & \textrm{ else}
\end{array}
\right.& \forall uv \in E
\end{align}

% Eq.~\ref{eq:fusion_move_a} can be solved efficiently, since 
% we can work on a coarser graph, where all nodes which are connected
% via must-link constraints are merged into single nodes.
% This coarser graph is constructed by contracting all must-link edges
% (see Fig.~\ref{fig:move_graph}).


% \begin{definition}\emph{(Back Projection)}
% Given a segmentation $\bar{y}$ of a contradicted graph $G_y=(V_y,E_y)$.
% We define the back projection $\rho^G$ from $\bar{y}$ to a segmentation of original graph  $G=(V,E)$
% by 
% \begin{align}
% \rho^G_{uv}(\bar{y})=\left\{ 
% \begin{array}{ll}
% \bar{y}_{S(u)S(v)}& \textrm{ if }S(u) \neq S(v)\\
% 0                & \textrm{ else}
% \end{array}
% \right.
% \end{align}
% \end{definition}

\begin{theorem}[Equivalence]\label{thm:Equivalence}
The back projection of the optimal segmentation $\bar{y}'$ of the contracted graph $G_y=(V_y,E_y, \bar{w})$
is an optimal solution of problem~\ref{eq:fusion_move_a}.
\begin{proof}
Let $y'$ be the back propagation of $\bar{y}'$, which is by definition feasible for~\ref{eq:fusion_move_a}.
If $y'$ would not be an optimal solution there must be a $y''$ with 
$\sum_{e\in E} w_ey_e' > \sum_{e\in E} w_ey_e''$.
Since $y_e'$ and $y_e''$ are $0$ for all $e \in \mathcal{E}_0^{\breve{y}}$ we would have
\begin{align*}
  \sum_{\bar{e}\in E_y} \bar{w}_{\bar{e}}\bar{y}'_{\bar{e}}
 &= \sum_{e\in E \setminus \mathcal{E}_0^{\breve{y}}} w_ey_e'          
  = \sum_{e\in E} w_ey_e' \\
 &> \sum_{e\in E} w_ey_e''
  = \sum_{e\in E \setminus \mathcal{E}_0^{\breve{y}}} w_ey_e''
  =\sum_{\bar{e}\in E_y} \bar{w}_{\bar{e}}\bar{y}''_{\bar{e}}
\end{align*}
where $\bar{y}''$ is the projection from $y''$ on $G_y$.
This contradicts that $y'$ is a optimal segmentation of $G_y$.
\end{proof}
%
\end{theorem}

Instead of problem~\ref{eq:fusion_move_a} we can now solve problem~\ref{eq:edgeproblem} on the contracted graph $G_{\breve{y}}$.
This is, depending on the intersection of the current and proposed solution, magnitudes smaller than $G$.
The correlation clustering problem on $G_{\breve{y}}$ can be solved by any correlation clustering solver.
Since $G_{\breve{y}}$ is smaller exact methods or good approximative methods like 
multicuts~\cite{kappes_2013_arxiv} or CGC~\cite{beier_2014_cvpr}
are very fast.

\input{inputs/fig_contraction.tex}
%\input{inputs/fig_projection.tex}



\input{inputs/fig_move_graph.tex}


%-------------------------------------------------------------------------
\subsection{Polyhedral Interpretation}
A polyhedral interpretation of fusion moves is shown in Fig.~\ref{fig:polyheadral}.
In each iteration the current and proposed segmentation define an inner polyhedral 
approximation of the original polytope. This interpretation holds for original 
fusion moves~\cite{Lempitsky-2010} as well as for the proposed CC-Fusion.

In our case, optimizing over the inner polytope is the same kind of problem as the original multicut polytope, but much smaller.
Furthermore, the cost do not change and an improvement in the smaller polytope will 
be the same in the original graph, as shown in Theorem~\ref{thm:Equivalence}.

The choice of the proposal defines the shape of the inner polytope. 
In the given toy example, the first (red) polytope give a huge improvement, the second proposal
defines the blue polytope which does not lead to an improvement. 
The third proposal generates the green polytope that includes the globally optimal solution.

This procedure is fundamentally different from common polyhedral multicut methods~\cite{kappes_2011_emmcvpr,kappes_2013_arxiv}, 
which tighten an outer relaxation of the multicut polytope and contrary to our method do not operate in the feasible domain. 



\begin{figure}
\centering
\input{polytope-tikz.tex}
\caption{Each move can be interpreted as an optimization of an inner polytope.
Each inner polytope includes the current vertex. Starting with $y_0$ we optimize over the red polytope 
and find $y_1$ as optima. When optimize over the blue polytope we stay in $y_1$ as optima.
When optimizing over the green polytope we find $y_2$ which we will never leave again or any polytope containing~$y_2$. 
}
\label{fig:polyheadral}
\end{figure}





% \begin{theorem}[Monotone]
% Let $y'$ and $y''$ be two proposal solutions and  $y^*$ the optimal fused segmentation.
% Than $y^*$  will never decrease the energy:
% $y^* \cdot w \leq  \min( y'\cdot w,  y''\cdot w) $ 
% %
% \begin{proof}
% The feasible set of the fusion move includes per definition  $y'$ and $y''$.
% If $y'$ or $y''$ would have lower multicut cost than $y^*$, $y^*$ would not be optimal 
% and that why not the propose segmentation of a fusion.
% \end{proof}
% %
% \end{theorem}


%\begin{remark}[Fix-point (pointless to me)]
%Let $Y$ be the set of possible proposals, than
%$y'$ is a fix-point if $y'=\arg\max_{y\in P(G_{y'\OR y''})} y\cdot w$ for all $y''\in Y$
%\end{remark}



% \begin{remark}[Optimality]
% Let $y'$ be the current and $y''$ the proposed segmentation.
% If the optimal solution $y^*$ lies in $P(G_{y' \OR y''})$ than a optimal fusion move will return $y^*$.
% \end{remark}

%-------------------------------------------------------------------------
\subsection{Proposal Generators}

As discussed in~\cite{Lempitsky-2010}, proposals
should have two properties: \emph{quality} 
and \emph{diversity}.

A proposal has a high quality if it at least in some regions has a low energy.
For high quality proposals the chance that the inner polytope includes a
better solution (vertex) is larger than for those with low quality.

Diversity between the individual proposals increases the chances
to span diverse internal polytopes, cover with the intersection of
inner polytopes a large part of the original polytope and find 
more likely the global optimal solution or escape from local minima.

For correlation clustering fusion we add a third
property: \emph{size}.
The size of the contracted graph directly
depends on the number of connected components
of the intersection of the proposal solution and the current best solution.
%
In the extreme case, where each 
node is in a separate connnected component,
the fusion move is equivalent to solving the original problem.
In the other extreme, where the proposal has 
a single connected component, the current best solution will not change.
% 
Therefore the size of the proposals
should be small enough, such that solving
eq.~\ref{eq:fusion_move_a} can
be done fast enough, but  on the other side 
large enough to define a large internal polytope and therefore a powerful move.
%
To this end we suggest two proposal generators.


%\begin{algorithm}
%    \begin{scriptsize}
%        \caption{Proposal Generators}\label{alg:proposal_gen}   
%        \begin{algorithmic}[1]
%            %\Require $J(x) \leq J(x')$
%            %\Ensure $J(\hat{x}) \leq J(x)$
%            %\vspace{0.3cm}
%            \Procedure{Rand2Coloring}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $x'= \argmin\limits_{\bar{x}} \sum\limits_{e_{ij} \in E } \tilde{w}_{ij}[\bar{x}_i \neq \bar{x}_j]  [x_i = x_j]   $
%
%            $ \quad\quad s.t.\quad x_i \in \{0, 1\} \forall i $
%            \State \textbf{return} $x'$
%            \EndProcedure
%            %
%            %
%            \vspace{0.3cm}
%            \Procedure{RandEdgeWeightedWatersheds}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $ getRandomSeeds$
%            \State $ runEdgeWeightedWs$
%            \EndProcedure   
%            %
%            %
%            \vspace{0.3cm}
%            \Procedure{RandHierarchicalClustering}{$x,G=(E,V),W$}
%            \State $\tilde{W} \gets \textbf{\scriptsize{randomize}}(W) $
%            \State $\hat{G}=(\hat{E},\hat{V}) \gets G=(E,V)$
%            \State $\hat{W} \gets W$
%            \While{$|\hat{V}|>\gamma$ \textbf{and}  $\max(\hat{W})>\theta$ }
%                \State $\hat{G}=(\hat{E},\hat{V}),\hat{W} \gets 
%                    \textbf{\scriptsize{contract}}(\hat{G},\hat{W},  \argmax\limits_{\hat{E}}(\hat{W}) )$
%            \EndWhile
%            \State $x' \gets \textbf{\scriptsize{getClusterResults}}(???) $ 
%            \EndProcedure
%        \end{algorithmic}
%    \end{scriptsize}
%\end{algorithm}



\noindent \textbf{Randomized HierarchicalClustering (RHC):}
%\subsubsection{Randomized HierarchicalClustering (RHC)}
%
To generate fast energy aware proposals we can use energy
based hierarchical clustering (EHC) as defined in Sec.~\ref{sec:ehc}.
EHC follows the energy function, therefore the \emph{quality}
of the proposals is high.
To get \emph{diversity} among the different proposal,
we add normally distributed noise  $\mathcal{N}(0, \sigma_{ehc})$
to each edge weight.
To get proposals of the desired \emph{size}, we use a
different stop condition as in EHC, and stop iff a certain number of connected
components is reached.

%\subsubsection{Randomized MaxCut  (RMC)}
%
%To get energy aware proposals we can use max cuts.
%The max cut objective is the same as
%the multicut objective, but only two 
%node colors are allowed.
%Therefore solutions of the max cut objective
%might be useful proposals.
%To create different proposals we set 
%the weight of edges which are cut 
%in the best solution to zero.
%In this way we favor solutions 
%different form the current best. 
%In addition we either add noise permute a certain number of weights.

\noindent \textbf{Randomized Watersheds (RWS):}
%\subsubsection{Randomized Watersheds (RWS)}
Watersheds have become quite popular for
graph segmentation and have a strong connection
to energy minimization~\cite{couprie_2011}.
%
The edge weighted watershed algorithm~\cite{meyer_2013}
with random seeds can be used to get
cheap proposals.
To improve \emph{quality} we do not use $n$ seeds distributed uniformly
over all nodes but use the following.
%
We draw $n/2$ negative edges, and assign different seed to the endpoints
of each edge.
Doing so, a random subset of negative edges is forced
to be cut within each proposal.
For additional \emph{diversity}, noise $\mathcal{N} (0, \sigma_{ws})$
is added to the edge weighs \cite{straehle_2012}.

%\input{inputs/fig_hc.tex}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Experiments}\label{sec:exp}
In our experiments we compare to the following methods with publicly available implementation.
%
For \textbf{CGC}~\cite{beier_2014_cvpr} we used the publicly available implementation\footnote{\label{opengm-cvpr2014}{\url{github.com/opengm/opengm/tree/cgc-cvpr2014}}} and for \textbf{KL}~\cite{Kernighan-1970} the implementation in OpenGM\footlabel{opengm-master}{\url{github.com/opengm/opengm}}.
For integer multicuts (\textbf{MC-I}) and relaxed multicuts (\textbf{MC-R})~\cite{kappes_2013_arxiv} we use a modified version of
 the publicly available implementation in OpenGM\footref{opengm-master}, as described in Sec.~\ref{sec:tunedMC}.
%
%We realize that their implementation has some limitations on large problems and make the following modifications.
%Firstly, we use \emph{index-min-heap}~\cite{Sedgewick-2011} within the shortest path search by the Dykstra algorithm - this gives a speed up for MC-R.
%Secondly, we follow~\cite{kroeger_2012_eccv} and search for shortest paths and add those only if they are non-chordal instead of searching for the shortest non-chordal path
%during the separation procedure. Fig.~\ref{fig:at:knott-450b} show the improvements with our modifications compared to the implementation in OpenGM for the knott-3d-450 dataset.
%This procedure is one magnitude faster, but might cause a few extra outer iterations.
%In~\cite{kroeger_2012_eccv}. this has been used for MC-I only. 
%For MC-R this search procedure is not sufficient and need to be followed by a search for a shortest non-chordal paths.
%
From the field of data-mining we compare to the PIVOT-algorithm~\cite{Ailon-2008} followed by a round of BOEM~\cite{Gionis-2007} denoted by \textbf{PIVOT-BOEM}.
We use the publicly available code\footnote{\url{http://www.ling.ohio-state.edu/~melsner/resources/correlation-readme.html}}.
While this implementation uses full adjacency matrices it does not scale as well and can not be applied on all datasets.
We also run classical fusion moves~\cite{Lempitsky-2010} (\textbf{Fusion}) and select distinct labels for the two candidate segmentations.
%
As reported in~\cite{beier_2014_cvpr}, CGC is faster and gives better energies than PlanarCC~\cite{yarkony_2012_eccv} and Expand \& Explore~\cite{bagon_2011_arxiv}.
Therefore we exclude those in our experiments.

We compare these methods to the following methods suggested in the present paper.
%
Energy Based Based Hierarchical Clustering (\textbf{EHC}),
as described in Sec.~\ref{sec:ehc}.
%
CGC warm started with the solution from EHC denoted by \textbf{EHC-CGC}.
%
The proposed correlation cluster fusion algorithm with EHC-based and watershed-based proposals
 and MC-I and CGC as subproblem solvers denoted by 
\textbf{CC-Fusion-HC-MC},
\textbf{-HC-CGC},
\textbf{-WS-MC}, and 
\textbf{-WS-CGC}, respectively.
We set the size of the proposals to $10\%$ of the original problem size
and use random edge noise with $\sigma=1.5$.
%
As stopping condition we choose $10^4$ iterations and $100$ iterations with no improvement.

All experiments were run on Intel Core i5-4570 CPUs
with 3.20 GHz, equipped with 32 GB of RAM.
In our evaluation we make no use of multiple threads.
The methods were stopped if they exceed 30 minutes at the next possible interrupt point.

% An overview of the used datasets is given in Tab.~\ref{tab:instance_sizes} and described in detail in Sec.\ref{sec:nets} and \ref{sec:imseg}.

% \begin{table}[th]
%    \tiny
%    \centering
%    \caption{Datasets used for evaluation}
%    \label{tab:instance_sizes}
%    \begin{tabular}{llllc}
%       \toprule
%          Dataset          &     \#Nodes     & \#Edges  & \#Instances  & Planar        \\ 
%       \midrule 
%          image-seg        &     156-3764        & ???              & 100          & $\bullet$    \\ 
%          knott-150        &     572-972         & ???              & 2            & $\times$ \\
%          knott-300        &     3846 - 5896     & ???              & 2            & $\times$ \\
%          knott-450        &     15150-17070     & ???              & 2            & $\times$ \\
%          knott-550        &     27286 - 31249   & ???              & 2            & $\times$ \\
%          3d-seg           &     101220          & ???              & 1            & $\times$ \\
%          socialnets       &     77350 - 131828  & 516575 - 841372  & 2            & $\times$ \\  
%       \bottomrule
%    \end{tabular}
% \end{table}

\input{datasets.tex}

\subsection{Improvements for the Multicut Algorithm}\label{sec:tunedMC} 
When using the  publicly available implementation in OpenGM\footref{opengm-master}
of Kappes~\etal~\cite{kappes_2013_arxiv}, we have realize that their implementation has some limitations on large problems.
This results in a very slow separation and we make the following modifications.
Firstly, we use \emph{index-min-heap}~\cite{Sedgewick-2011} within the shortest path search by the Dykstra algorithm - this gives a speed up for MC-R.
Secondly, we follow~\cite{kroeger_2012_eccv} and search for shortest paths and add those only if they are non-chordal instead of searching for the shortest non-chordal path
during the separation procedure. 
In~\cite{kroeger_2012_eccv} this has been used for MC-I only. 
For MC-R this search procedure is not sufficient and needs to be followed by a search for shortest non-chordal paths.
%
Fig.~\ref{fig:at:knott-450b} shows the improvements with our modifications compared to the implementation in OpenGM for the knott-3d-450 dataset.
This procedure is one magnitude faster, but might cause a few extra outer iterations.

 \begin{figure}[t]
    \centering
    \begin{tikzpicture}
    \begin{semilogxaxis}[  mark size=1pt,
     height= 4cm, 
    restrict y to domain=-80000:1000,
   %   restrict x to domain=10:4000,
    xlabel = {runtime},
    xmin = 10,
    xmax = 4100,
    ymax = 0,
    ymin = -80000,
    legend to name = ledgendPositionMC,
    legend columns=4,
    width = 0.9\columnwidth,
    scaled ticks = false
    ] 
    \addplot[color=red,mark=x] table[x=time, y=MC-CCFDB-o*]{data3/knott-3d-450b.data};          \addlegendentry{MCR-old}
    \addplot[color=orange,mark=o] table[x=time, y=MC-CCFDB-n*]{data3/knott-3d-450b.data};          \addlegendentry{MCR-new}
    \addplot[color=blue,mark=x] table[x=time, y=MC-CCIFD-o*]{data3/knott-3d-450b.data};          \addlegendentry{MCI-old}
    \addplot[color=cyan,mark=o] table[x=time, y=MC-CCIFD-n*]{data3/knott-3d-450b.data};          \addlegendentry{MCI-new}

    \end{semilogxaxis}
    \end{tikzpicture}
  \begin{center}
  \hypersetup{linkcolor = black}
  \ref{ledgendPositionMC}
  \hypersetup{linkcolor = red}
  \end{center}
    \caption{Comparison of the Multicut implementation of OpenGM and 
    our modified implementation, which can deal better with large scale problems. 
    However, for large scale problems it still does not scale.}
    \label{fig:at:knott-450b}
  \end{figure}

\subsection{Parameter Choice for CC-Fusion}
Beside the choice of the proposal generator and fusion method CC-Fusion has some more parameters, which need to be set.
The most crucial one is the number of segments in the proposal. For HC we also have to set the noise which is used to generate diversity.
Fig.~\ref{fig:parameterchoice} shows an evaluation of the impact of this parameters for a single instance of knott-3d-450 averaged over several random seeds.
The runtime depends on the number of clusters in the proposal (Fig.~\ref{fig:parameterchoice} left), which controls the size of the auxiliary move problems.
The level of noise has no major impact on the runtime.
The energy of the final solution improves with finer proposals since this increase the search-space of the moves.
Although the level of noise has to be large enough to generate diverse proposals but also not to large to generate proposals with low quality.
As shown in Fig.~\ref{fig:parameterchoice} right the useful parameter set is quite large. This allows us to use the same parameters for \emph{all}
experiments. However we would like to note, that in practice we can improve the performance by adjust these parameters for the specific problem setting.
%
%
\begin{figure}[th]
\centering
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-time2.pdf}}
\fbox{\includegraphics[width=0.45\columnwidth,trim=3.5cm 8cm 4.5cm 8cm,clip]{images/grid-value2.pdf}}
\caption{Empirical evaluation of the impact of noise used for proposal generation and proposal size.
  Proposals with many segments causes longer runtime. Noise seemed not to be a critical parameter but should be selected large enough.
}
\label{fig:parameterchoice}
\end{figure}

\input{evaluation.tex}
% \subsection{Social Networks and Network Clustering}\label{sec:nets}
% An application for large scale correlation clustering are social networks.
% We consider two of those networks from the Stanford Large Network Dataset Collection\footnote{\url{http://snap.stanford.edu/data/index.html}}.
% Both networks are given by weighted directed graphs with edge weights $-1$ and $1$. 
% %
% The first network is called \emph{Epinions}. 
% This is who-trust-whom online social network of a a general consumer review site Epinions.com. 
% Each directed edge $a\to b$ indicated that user $a$ trusts  or does not trust user $b$ by a  positive or negative edge-weight, respectively.
% The network contains $131828$ nodes and $841372$ edges from which $85.3\%$ are positively weighted.
% %
% The second network is called \emph{Slashdot}. 
% Slashdot is a technology-related news website know for its specific user community. 
% In 2002 Slashdot introduced the Slashdot Zoo feature which allows users to tag each other as friends or foes. 
% The network was obtained in November 2008 and contains $77350$ nodes and $516575$ edges from which $76.73\%$ are positively weighted.

% We consider the problem to cluster this graphs such that positively weighted edges ($E^+_{\to}$) link inside and negatively weighted edges ($E^-_{\to}$) between clusters.
% In other words friends and people who trust each other should be in the same segment and foes and non-trusting people in different clusters.
% % 
% To compensate the high impact of nodes with high degree we can normalize the edge weights such that each person has the same impact to the overall network, by enforcing.
% \begin{align}
%   \sum_{i\to j \in E_{\to}} |w_{i\to j}| &= 1&\forall i\in V, deg^{\textrm{out}}(i)\geq 1 
% \end{align}
% We define the following energy function
% \begin{align}
%  J(y) &= \sum_{i\to j \in E^+_{\to}} y_{ij}\cdot w_{i \to j} +  \sum_{i\to j \in E^-_{\to}} (y_{ij}-1)\cdot w_{i \to j} \nonumber\\
%       &= \sum_{ij \in E} y_{ij}\cdot \underbrace{(w_{i \to j}+w_{j \to i})}_{w_{ij}} + \textrm{const}
% \end{align}
% which is zero if the given partitioning does not violated any relation and larger otherwise.
% We name this two datasets \emph{social nets} and \emph{normalized social nets}.

% As shown in Fig.~\ref{fig:anytime}(g,h) CC-Fusion provides for the first minutes the best results.
% Only CGC and HC-CGC are able to find better solutions after more then 1000 seconds.
% MC-I and MC-R can even not be applied on such large problems.
% We belief that with better proposal generators, which are more suited for such network problems,
% we can improve CC-Fusion. One candidate for such a generated would be a scalable implementations of the 
% PIVOT algorithm.

% As another example for network clustering we use the \emph{modularity-clustering} models from~\cite{kappes_2014_benchmark_arxiv} which are small but fully connected.
% Although, CC-Fusion and the used parameters was not designed and chosen for this type of problem, it performs on par to competitive methods. 
% Especially is does a better job than MC-I as shown in Fig.~\ref{fig:anytime}(i)



% \subsection{2D and 3D Image Segmentation}\label{sec:imseg}
% To segment images or volumes into a previously
% unknown number of clusters, correlation clustering
% has been used~\cite{andres_2011_iccv,kroeger_2012_eccv}.

% Starting from a super-pixel/-voxel segmentation,
% correlation clustering finds the clustering with the lowest energy.
% The energy is based on a likelihood of merging adjacent super-voxels.
% Each edge has a probability to keep adjacent segments separate ($p(y_{ij} =1)$)
% or to merge them ($p(y_{ij} = 0)$).
% The energy function is defined as following:
% \begin{align}
%  J(y)  &= \sum_{ij \in E} y_{ij}\cdot \underbrace{  log\left( \frac{p(y_{ij} =0)}{p(y_{ij} =1)}\right) + log \frac{1-\beta}{\beta}  }_{w_{ij}}
% \end{align}
% Where $\beta$ is used as a prior~\cite{andres_2011_iccv}.

% We use the public available benchmark instances from~\cite{kappes_2013_benchmark_cvpr,kappes_2014_benchmark_arxiv}.
% For 2D images, we took the segmentation problems on the Berkeley Segmentation Database~\cite{martin_2001} called \emph{image-seg}~\cite{andres_2011_iccv,kappes_2013_benchmark_cvpr}.
% For 3D volume segmentation we took the models \emph{knott-3d-150},\emph{-300} and \emph{-450} from~\cite{kroeger_2012_eccv,kappes_2014_benchmark_arxiv} as well as the large
% instance from the \emph{3d-seg} model~\cite{andres_2011_iccv,kappes_2013_benchmark_cvpr}. These instances have underling cube sizes of  $150^3$, $300^3$, $450^3$, and $900^3$, respectively.
% We also request larger instances from the authors of~\cite{kroeger_2012_eccv} which kindly provide us the dataset~\emph{knott-3d-550} with cube size  $550^3$.
% %More information of the size of instances is given in Tab.~\ref{tab:instance_sizes}.

% For image-seg CC-Fusion is faster than competitive methods, \cf Fig.~\ref{fig:anytime}(a).
% The variation of information~\cite{} (VI) of the CC-Fusion methods is also best, \cf Tab.~\ref{tab:eval}.
% Proposals by EHC seemed to be a bit better than WS-based ones.

% For the knott-datasets similar holds. With increasing problem size CC-Fusion-HC-MC and CC-Fusion-WS-MC have a better performance compared to competitive methods, \cf Fig.~\ref{fig:anytime}(b-e).
% Also in terms of VI they are only slightly worse than the global optimal solution found by MC-I.
% The initialization of CGC by HC denoted by HC-CGC also improves the performance compared to native CGC.
% For the largest 3D volume seg-3d, HC-CGC gives the first good solution, \cf  Fig.~\ref{fig:anytime}(f).
% However, after a view minutes  CC-Fusion-HC-MC and CC-Fusion-WS-MC give much better results and also overall best in terms of energy and VI, \cf Tab.~\ref{tab:eval}.

% Pure HC, Fusion and PIVOT-BOEM do not give useful results on any dataset.

\begin{table}[t]
   \tiny
   \centering
   \caption{Evaluation by Variation of Information (VOI) Rand Index (RI) for datasets with available ground-truth.}
   \label{tab:eval}
   \begin{tabular}{lllllll}
      \toprule
         VOI              &  image-seg   & knott-3d-150 & knott-3d-300   & knott-3d-450 & knott-3d-550 &3d-seg\\
      \midrule 
         PIVOT-BOEM       &\rd$ 4.9633$  &\rd $ 2.9936$ &\rd $ 4.4986$   &      --      &    --        &  --\\ 
         HC               &   $ 2.5967$  &    $ 1.5477$ &    $ 2.3513$   &    $ 2.9155$ &    --        & $       2.8395$\\
         HC-CGC           &   $ 2.5164$  &    $ 0.9052$ &    $ 1.7636$   &    $ 2.2256$ &    --        & $       1.7603$ \\
         CGC              &   $ 2.5247$  &    $ 0.9267$ &    $ 1.8822$   &    $ 2.3104$ &    --        & $\rd    6.8908$ \\
         KL               &   $ 2.6432$  &\rd $ 2.0648$ &\rd $ 4.1318$   &\rd $ 4.9270$ &    --        & $\rd    7.1057$\\
         FUSION           &$\bf 2.1406$  &\rd $ 2.8787$ &\rd $ 4.0744$   &\rd $ 4.6616$ &    --        & $\rd    6.5366$ \\
         MC-R             &   $ 2.5471$  &    $ 0.9178$ &    $ 1.6369$   &    $ 2.8710$ &    --        & $\rd    6.5058$\\   
         MC-I             &   $ 2.5367$  & $\bf 0.9063$ & $\bf 1.6352$   & $\bf 2.0037$ &    --        & $\rd    4.3319$\\  
         CC-Fusion-HC-MC   &   $ 2.5319$  &    $ 0.9629$ &    $ 1.6516$   &    $ 2.0801$ &    --        & $\bf    1.3347$ \\  
         CC-Fusion-HC-CGC  &$\bf 2.4961$  &    $ 0.9679$ &    $ 1.7673$   &    $ 2.3809$ &    --        & $       2.1347$ \\  
         CC-Fusion-WS-MC   &   $ 2.5340$  &    $ 0.9629$ &    $ 1.6742$   &    $ 2.0739$ &    --        & $\bf    1.3334$ \\  
         CC-Fusion-WS-CGC  &   $ 2.5192$  &    $ 1.0585$ &    $ 2.1344$   &    $ 2.7487$ &    --        & $       3.3514$ \\      
      \bottomrule
   \end{tabular}

   \begin{tabular}{lllllll}
      \toprule
          RI              &  image-seg   & knott-3d-150 & knott-3d-300   & knott-3d-450 & knott-3d-550 &3d-seg\\
      \midrule 
         PIVOT-BOEM       &   $ 0.7438$  &\rd $ 0.7851$ &    $  0.8792$  &      --      &    --        &  --\\ 
         HC               &   $ 0.7560$  &\rd $ 0.8139$ &\rd $  0.8084$  &\rd $ 0.7610$ &    --        &   $ 0.9651$\\
         HC-CGC           &   $ 0.7724$  &    $ 0.9226$ &    $  0.8713$  &    $ 0.8433$ &    --        &   $ 0.9861$ \\
         CGC              &   $ 0.7590$  &    $ 0.9206$ &    $  0.8666$  &    $ 0.8341$ &    --        &\rd$ 0.6024$ \\
         KL               &\rd$ 0.6400$  &\rd $ 0.8085$ &\rd $  0.6858$  &\rd $ 0.6409$ &    --        &\rd$ 0.5849$\\
         FUSION           &\rd$ 0.5480$  &\rd $ 0.2849$ &\rd $  0.1420$  &\rd $ 0.0998$ &    --        &\rd$ 0.0345$ \\
         MC-R             &   $ 0.7822$  &    $ 0.9232$ & $\bf  0.8849$  &\rd $ 0.6713$ &    --        &\rd$ 0.0432$ \\   
         MC-I             &   $ 0.7821$  & $\bf 0.9236$ & $\bf  0.8849$  & $\bf 0.8670$ &    --        &\rd$ 0.5461$\\  
         CC-Fusion-HC-MC   &   $ 0.7801$  &    $ 0.9042$ &    $  0.8824$  &    $ 0.8573$ &    --        &$\bf 0.9906$ \\  
         CC-Fusion-HC-CGC  &   $ 0.7780$  &    $ 0.9031$ &    $  0.8763$  &    $ 0.8470$ &    --        &   $ 0.9775$ \\  
         CC-Fusion-WS-MC   &$\bf 0.7825$  &    $ 0.9042$ &    $  0.8802$  &    $ 0.8582$ &    --        &   $ 0.8895$ \\  
         CC-Fusion-WS-CGC  &   $ 0.7750$  &    $ 0.8951$ &    $  0.8596$  &    $ 0.8394$ &    --        &   $\bf 0.9906$ \\      
      \bottomrule
   \end{tabular}
\end{table}

%\begin{center}
%    \begin{figure}
%        \begin{center}
%            \begin{subfigure}[b]{0.45\linewidth}
%                \includegraphics[width=1.0\linewidth]{images/-010.jpg}
%            \end{subfigure}
%            \quad
%            \begin{subfigure}[b]{0.45\linewidth}
%                \includegraphics[width=1.0\linewidth]{images/-030.jpg}
%            \end{subfigure}
%        \end{center}
%    \caption{
%        Raw FIBSEM data and correlation clustering result of the model from \cite{kroeger_2012_eccv%}
%    }
%    \end{figure}
%\end{center}
%
%\newpage



\input{anytimefigure2.tex}


% \begin{figure}
% \input{scatterplots/knott-3d-450.tex}
% \caption{Values and runtime for the 8 knott-3d-450 instances. Note that we use for DYNCC a defensive stopping condition.
% A more aggressive one would lead to much faster runtime with only a bit worse values.
% DYNCC find solutions with less than distance 100 to the optimum a magnitude faster than the state of the art, which produce poor results on hard instances with a 1 hour time limit.
% }
% \end{figure}



%\subsection{Pixel-wise Multicuts}
%\input{inputs/fig_pixel_mc.tex}


\section{Future Work}\label{sec:future}
In future work we would like to investigate in much larger problem instances
and interactive correlation clustering, by enforcing
updates only in local regions by appropriate proposals.
%
Within this challenging task we can also enforce additionally must-not-link constraints in eq.~\ref{eq:fusion_move_a}.
If those build a closed surface, the problem decompose into two independent problems.
%
Overall, a more specific selection of proposals, maybe conditioned on the current solution,
should lead better proposals and to faster progress of CC-Fusion.
%
Furthermore, we can extend our approach to higher-order correlation clustering~\cite{Kim-2011,kappes_2013_arxiv}
by using higher order subproblems.


\section{Conclusion}\label{sec:conclusion}

We have presented a fast and scalable 
approximate solver for correlation 
clustering, named Correlation Clustering Fusion (CC-Fusion).
It is orthogonal to previous research, \ie it can be combined with and
correlation clustering solver.
%
The best solution is iteratively improved 
by a fusion with proposal solutions.
The fusion move itself is formulated as correlation
clustering on a smaller graph fewer edges and nodes
and can therefore be solved much faster than the original problem.

Our evaluation shows that several CC-Fusion
outperforms state-of-the-art solvers w.r.t. any time performance 
with increasing problem size.


    


\newpage

\FloatBarrier
{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

% \newpage

% \onecolumn
% \section{Appendix}

% \input{tables/anytime/image-seg.tex}
% \input{tables/anytime/knott-3d-150.tex}
% \input{tables/knott-3d-300.tex}
% \input{tables/anytime/knott-3d-450.tex}
% \input{tables/knott-3d-550.tex}
% \input{tables/anytime/seg-3d.tex}
% \input{tables/modularity-clustering.tex}



\end{document}
